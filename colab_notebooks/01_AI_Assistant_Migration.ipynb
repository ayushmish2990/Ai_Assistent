{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushmish2990/ai_chatbot_backend/blob/main/colab_notebooks/01_AI_Assistant_Migration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üöÄ AI Coding Assistant - Colab Migration\n",
        "\n",
        "This notebook migrates your AI Coding Assistant project to Google Colab environment.\n",
        "\n",
        "## Features:\n",
        "- ‚úÖ Complete project setup in Colab\n",
        "- ‚úÖ FastAPI backend with ngrok tunneling\n",
        "- ‚úÖ AI service integration\n",
        "- ‚úÖ Database setup and management\n",
        "- ‚úÖ File persistence with Google Drive\n",
        "\n",
        "## Prerequisites:\n",
        "1. Enable GPU runtime (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
        "2. Mount Google Drive for persistence\n",
        "3. Have your OpenAI API key ready\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "setup_environment",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f35c28ec-aacb-4ffd-dd4b-1194c1820efb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.116.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.12/dist-packages (0.35.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.47.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]) (0.16.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard])\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]) (6.0.2)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard])\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard])\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]) (15.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvloop, httptools, watchfiles\n",
            "Successfully installed httptools-0.6.4 uvloop-0.21.0 watchfiles-1.1.0\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (2.0.43)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.12/dist-packages (1.16.5)\n",
            "Requirement already satisfied: pydantic[email] in /usr/local/lib/python3.12/dist-packages (2.11.7)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (4.15.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic) (1.3.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic[email]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic[email]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic[email]) (0.4.1)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email])\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email])\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator>=2.0.0->pydantic[email]) (3.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic) (3.0.2)\n",
            "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, email-validator\n",
            "Successfully installed dnspython-2.8.0 email-validator-2.3.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.3.0\n",
            "Mounted at /content/drive\n",
            "‚úÖ Working directory: /content/drive/MyDrive/ai-coding-assistant\n"
          ]
        }
      ],
      "source": [
        "# üì¶ Install Required Packages\n",
        "!pip install fastapi uvicorn[standard] openai python-dotenv\n",
        "!pip install sqlalchemy alembic pydantic[email]\n",
        "!pip install transformers torch datasets\n",
        "!pip install pyngrok\n",
        "\n",
        "# Mount Google Drive for persistence\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Create project directory in Google Drive\n",
        "project_path = '/content/drive/MyDrive/ai-coding-assistant'\n",
        "os.makedirs(project_path, exist_ok=True)\n",
        "os.chdir(project_path)\n",
        "\n",
        "print(f'‚úÖ Working directory: {os.getcwd()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "clone_repository",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f51d58-0fd6-4415-8df2-e0b43e205f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Project structure created\n"
          ]
        }
      ],
      "source": [
        "# üì• Clone or Update Repository\n",
        "\n",
        "# Option 1: Clone from GitHub (if you have a repo)\n",
        "# !git clone https://github.com/yourusername/ai-coding-assistant.git .\n",
        "\n",
        "# Option 2: Create project structure manually\n",
        "import os\n",
        "\n",
        "# Create directory structure\n",
        "directories = [\n",
        "    'backend/app/api/v1',\n",
        "    'backend/app/core',\n",
        "    'backend/app/services',\n",
        "    'backend/app/models',\n",
        "    'backend/app/schemas',\n",
        "    'backend/app/crud',\n",
        "    'backend/app/db',\n",
        "    'data/raw',\n",
        "    'data/processed',\n",
        "    'data/models',\n",
        "    'logs',\n",
        "    'notebooks',\n",
        "    'scripts'\n",
        "]\n",
        "\n",
        "for directory in directories:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    # Create __init__.py files for Python packages\n",
        "    if 'backend/app' in directory:\n",
        "        with open(f'{directory}/__init__.py', 'w') as f:\n",
        "            f.write('')\n",
        "\n",
        "print('‚úÖ Project structure created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "create_config",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "355f7d08-19dc-47a3-9e2b-6dd9140e28fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuration files created\n"
          ]
        }
      ],
      "source": [
        "# ‚öôÔ∏è Create Configuration Files\n",
        "\n",
        "# Create .env file\n",
        "env_content = '''\n",
        "# OpenAI Configuration\n",
        "OPENAI_API_KEY=your_openai_api_key_here\n",
        "OPENAI_MODEL=gpt-3.5-turbo\n",
        "\n",
        "# Database Configuration\n",
        "DATABASE_URL=sqlite:///./ai_assistant.db\n",
        "\n",
        "# API Configuration\n",
        "API_V1_STR=/api/v1\n",
        "PROJECT_NAME=AI Coding Assistant\n",
        "\n",
        "# Security\n",
        "SECRET_KEY=your-secret-key-here\n",
        "ACCESS_TOKEN_EXPIRE_MINUTES=30\n",
        "'''\n",
        "\n",
        "with open('backend/.env', 'w') as f:\n",
        "    f.write(env_content.strip())\n",
        "\n",
        "# Create requirements.txt\n",
        "requirements = '''\n",
        "fastapi==0.104.1\n",
        "uvicorn[standard]==0.24.0\n",
        "openai==1.3.0\n",
        "python-dotenv==1.0.0\n",
        "sqlalchemy==2.0.23\n",
        "alembic==1.12.1\n",
        "pydantic[email]==2.5.0\n",
        "python-multipart==0.0.6\n",
        "httpx==0.24.1\n",
        "transformers==4.35.0\n",
        "torch==2.1.0\n",
        "datasets==2.14.0\n",
        "'''\n",
        "\n",
        "with open('backend/requirements.txt', 'w') as f:\n",
        "    f.write(requirements.strip())\n",
        "\n",
        "print('‚úÖ Configuration files created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "create_backend_core",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b583a14-89dd-417a-8cd4-a8fb98258faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Backend core files created\n"
          ]
        }
      ],
      "source": [
        "# üèóÔ∏è Create Backend Core Files\n",
        "\n",
        "# Create config.py\n",
        "config_content = '''\n",
        "from pydantic_settings import BaseSettings\n",
        "from typing import Optional\n",
        "\n",
        "class Settings(BaseSettings):\n",
        "    # OpenAI Settings\n",
        "    OPENAI_API_KEY: str\n",
        "    OPENAI_MODEL: str = \"gpt-3.5-turbo\"\n",
        "\n",
        "    # Database Settings\n",
        "    DATABASE_URL: str = \"sqlite:///./ai_assistant.db\"\n",
        "\n",
        "    # API Settings\n",
        "    API_V1_STR: str = \"/api/v1\"\n",
        "    PROJECT_NAME: str = \"AI Coding Assistant\"\n",
        "\n",
        "    # Security\n",
        "    SECRET_KEY: str\n",
        "    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30\n",
        "\n",
        "    class Config:\n",
        "        env_file = \".env\"\n",
        "\n",
        "settings = Settings()\n",
        "'''\n",
        "\n",
        "with open('backend/app/core/config.py', 'w') as f:\n",
        "    f.write(config_content.strip())\n",
        "\n",
        "# Create main.py\n",
        "main_content = '''\n",
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from app.api.v1.api import api_router\n",
        "from app.core.config import settings\n",
        "\n",
        "app = FastAPI(\n",
        "    title=settings.PROJECT_NAME,\n",
        "    openapi_url=f\"{settings.API_V1_STR}/openapi.json\"\n",
        ")\n",
        "\n",
        "# Set up CORS\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "app.include_router(api_router, prefix=settings.API_V1_STR)\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"AI Coding Assistant API\", \"status\": \"running\"}\n",
        "'''\n",
        "\n",
        "with open('backend/app/main.py', 'w') as f:\n",
        "    f.write(main_content.strip())\n",
        "\n",
        "print('‚úÖ Backend core files created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "create_ai_service",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17d65c5-9fc5-4f99-8371-5935049be73a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ AI service created\n"
          ]
        }
      ],
      "source": [
        "# ü§ñ Create AI Service\n",
        "\n",
        "ai_service_content = '''\n",
        "import openai\n",
        "from app.core.config import settings\n",
        "from typing import List, Dict, Any\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class AIService:\n",
        "    def __init__(self):\n",
        "        self.client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)\n",
        "        self.model = settings.OPENAI_MODEL\n",
        "        logger.info(f\"AI Service initialized with model: {self.model}\")\n",
        "\n",
        "    async def generate_code(self, prompt: str, language: str = \"python\") -> str:\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": f\"You are a helpful coding assistant. Generate {language} code based on the user's request.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=1000,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            if \"insufficient_quota\" in str(e) or \"429\" in str(e):\n",
        "                return \"I apologize, but the AI service is currently experiencing quota limitations. Please try again later or check your API key settings.\"\n",
        "            logger.error(f\"Error generating code: {e}\")\n",
        "            return f\"Error generating code: {str(e)}\"\n",
        "\n",
        "    async def suggest_completion(self, code: str, cursor_position: int) -> str:\n",
        "        try:\n",
        "            prompt = f\"Complete this code:\\n{code}\\n\\nCursor position: {cursor_position}\"\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a code completion assistant. Provide the most likely completion for the given code.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=200,\n",
        "                temperature=0.3\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            if \"insufficient_quota\" in str(e) or \"429\" in str(e):\n",
        "                return \"AI completion temporarily unavailable due to quota limits.\"\n",
        "            logger.error(f\"Error suggesting completion: {e}\")\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "    async def chat_with_context(self, message: str, context: List[Dict[str, Any]] = None) -> str:\n",
        "        try:\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI coding assistant. Help users with programming questions, code review, and development tasks.\"}\n",
        "            ]\n",
        "\n",
        "            if context:\n",
        "                for ctx in context[-5:]:  # Last 5 messages for context\n",
        "                    messages.append(ctx)\n",
        "\n",
        "            messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=messages,\n",
        "                max_tokens=1500,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            if \"insufficient_quota\" in str(e) or \"429\" in str(e):\n",
        "                return \"I'm currently experiencing quota limitations. Please try again later or consider upgrading your OpenAI plan.\"\n",
        "            logger.error(f\"Error in chat: {e}\")\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "# Global AI service instance\n",
        "ai_service = AIService()\n",
        "'''\n",
        "\n",
        "with open('backend/app/services/ai_service.py', 'w') as f:\n",
        "    f.write(ai_service_content.strip())\n",
        "\n",
        "print('‚úÖ AI service created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "create_api_routes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf4db0c3-028f-4b41-c9a5-ebf9ee478767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API routes created\n"
          ]
        }
      ],
      "source": [
        "# üõ£Ô∏è Create API Routes\n",
        "\n",
        "# Create API router\n",
        "api_router_content = '''\n",
        "from fastapi import APIRouter\n",
        "from app.api.v1.endpoints import ai, codebase\n",
        "\n",
        "api_router = APIRouter()\n",
        "api_router.include_router(ai.router, prefix=\"/ai\", tags=[\"ai\"])\n",
        "api_router.include_router(codebase.router, prefix=\"/codebase\", tags=[\"codebase\"])\n",
        "'''\n",
        "\n",
        "os.makedirs('backend/app/api/v1/endpoints', exist_ok=True)\n",
        "with open('backend/app/api/v1/endpoints/__init__.py', 'w') as f:\n",
        "    f.write('')\n",
        "\n",
        "with open('backend/app/api/v1/api.py', 'w') as f:\n",
        "    f.write(api_router_content.strip())\n",
        "\n",
        "# Create AI endpoints\n",
        "ai_endpoints_content = '''\n",
        "from fastapi import APIRouter, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from app.services.ai_service import ai_service\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "router = APIRouter()\n",
        "\n",
        "class CodeGenerationRequest(BaseModel):\n",
        "    prompt: str\n",
        "    language: str = \"python\"\n",
        "\n",
        "class CompletionRequest(BaseModel):\n",
        "    code: str\n",
        "    cursor_position: int\n",
        "\n",
        "class ChatRequest(BaseModel):\n",
        "    message: str\n",
        "    context: Optional[List[Dict[str, Any]]] = None\n",
        "\n",
        "@router.post(\"/generate-code\")\n",
        "async def generate_code(request: CodeGenerationRequest):\n",
        "    try:\n",
        "        result = await ai_service.generate_code(request.prompt, request.language)\n",
        "        return {\"code\": result, \"status\": \"success\"}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@router.post(\"/suggest-completion\")\n",
        "async def suggest_completion(request: CompletionRequest):\n",
        "    try:\n",
        "        result = await ai_service.suggest_completion(request.code, request.cursor_position)\n",
        "        return {\"completion\": result, \"status\": \"success\"}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@router.post(\"/chat\")\n",
        "async def chat(request: ChatRequest):\n",
        "    try:\n",
        "        result = await ai_service.chat_with_context(request.message, request.context)\n",
        "        return {\"response\": result, \"status\": \"success\"}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "'''\n",
        "\n",
        "with open('backend/app/api/v1/endpoints/ai.py', 'w') as f:\n",
        "    f.write(ai_endpoints_content.strip())\n",
        "\n",
        "# Create codebase endpoints\n",
        "codebase_endpoints_content = '''\n",
        "from fastapi import APIRouter\n",
        "\n",
        "router = APIRouter()\n",
        "\n",
        "@router.get(\"/status\")\n",
        "async def get_codebase_status():\n",
        "    return {\"status\": \"active\", \"message\": \"Codebase service is running\"}\n",
        "\n",
        "@router.get(\"/health\")\n",
        "async def health_check():\n",
        "    return {\"status\": \"healthy\", \"service\": \"AI Coding Assistant\"}\n",
        "'''\n",
        "\n",
        "with open('backend/app/api/v1/endpoints/codebase.py', 'w') as f:\n",
        "    f.write(codebase_endpoints_content.strip())\n",
        "\n",
        "print('‚úÖ API routes created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "setup_ngrok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb028a7-b11b-4170-eb14-77b1bbf11e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ngrok setup ready\n"
          ]
        }
      ],
      "source": [
        "# üåê Setup Ngrok for External Access\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import uvicorn\n",
        "import time\n",
        "\n",
        "# Set your ngrok auth token (get it from https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "ngrok.set_auth_token(\"32lxmVvlcVwe0aIQldrGTv9sB0c_2kNsr5fcetExZj6St12dZ\")\n",
        "\n",
        "def start_server():\n",
        "    \"\"\"Start the FastAPI server\"\"\"\n",
        "    os.chdir('backend')\n",
        "    uvicorn.run(\"app.main:app\", host=\"0.0.0.0\", port=8000, reload=False)\n",
        "\n",
        "def setup_ngrok_tunnel():\n",
        "    \"\"\"Setup ngrok tunnel for external access\"\"\"\n",
        "    try:\n",
        "        # Create ngrok tunnel\n",
        "        public_url = ngrok.connect(8000)\n",
        "        print(f\"\\nüåê Your API is now accessible at: {public_url}\")\n",
        "        print(f\"üìã API Documentation: {public_url}/docs\")\n",
        "        print(f\"üîç Health Check: {public_url}/api/v1/codebase/health\")\n",
        "\n",
        "        return public_url\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error setting up ngrok: {e}\")\n",
        "        print(\"üí° You can still access the API locally at: http://localhost:8000\")\n",
        "        return \"http://localhost:8000\"\n",
        "\n",
        "print('‚úÖ Ngrok setup ready')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "start_application",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e604142-c439-4862-b7c0-790f2a65ceb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è  IMPORTANT: Update your OpenAI API key in backend/.env file\n",
            "üìù Edit the OPENAI_API_KEY value with your actual API key\n",
            "‚è≥ Starting server...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-09-16T19:43:12+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-09-16T19:43:12+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå Error setting up ngrok: The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n.\n",
            "üí° You can still access the API locally at: http://localhost:8000\n",
            "\n",
            "‚úÖ AI Coding Assistant is now running!\n",
            "\n",
            "üìö Available endpoints:\n",
            "  ‚Ä¢ POST http://localhost:8000/api/v1/ai/generate-code\n",
            "  ‚Ä¢ POST http://localhost:8000/api/v1/ai/suggest-completion\n",
            "  ‚Ä¢ POST http://localhost:8000/api/v1/ai/chat\n",
            "  ‚Ä¢ GET  http://localhost:8000/api/v1/codebase/status\n",
            "\n",
            "üîß Next steps:\n",
            "1. Update your OpenAI API key in backend/.env\n",
            "2. Test the API using the documentation link above\n",
            "3. Integrate with your frontend application\n",
            "4. Check the training pipeline notebook for custom model development\n"
          ]
        }
      ],
      "source": [
        "# üöÄ Start the Application\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add backend to Python path\n",
        "backend_path = os.path.join(os.getcwd(), 'backend')\n",
        "if backend_path not in sys.path:\n",
        "    sys.path.insert(0, backend_path)\n",
        "\n",
        "# Update your OpenAI API key in the .env file\n",
        "print(\"‚ö†Ô∏è  IMPORTANT: Update your OpenAI API key in backend/.env file\")\n",
        "print(\"üìù Edit the OPENAI_API_KEY value with your actual API key\")\n",
        "\n",
        "# Start the server in a separate thread\n",
        "server_thread = threading.Thread(target=start_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "# Wait for server to start\n",
        "print(\"‚è≥ Starting server...\")\n",
        "time.sleep(5)\n",
        "\n",
        "# Setup ngrok tunnel\n",
        "public_url = setup_ngrok_tunnel()\n",
        "\n",
        "print(\"\\n‚úÖ AI Coding Assistant is now running!\")\n",
        "print(\"\\nüìö Available endpoints:\")\n",
        "print(f\"  ‚Ä¢ POST {public_url}/api/v1/ai/generate-code\")\n",
        "print(f\"  ‚Ä¢ POST {public_url}/api/v1/ai/suggest-completion\")\n",
        "print(f\"  ‚Ä¢ POST {public_url}/api/v1/ai/chat\")\n",
        "print(f\"  ‚Ä¢ GET  {public_url}/api/v1/codebase/status\")\n",
        "\n",
        "print(\"\\nüîß Next steps:\")\n",
        "print(\"1. Update your OpenAI API key in backend/.env\")\n",
        "print(\"2. Test the API using the documentation link above\")\n",
        "print(\"3. Integrate with your frontend application\")\n",
        "print(\"4. Check the training pipeline notebook for custom model development\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "test_api",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc18919-9479-4026-b50b-3448ba6fe6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health check failed: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /api/v1/codebase/health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x782b22914680>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "Code generation test failed: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /api/v1/ai/generate-code (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x782b22411310>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "üí° Make sure to update your OpenAI API key in backend/.env\n"
          ]
        }
      ],
      "source": [
        "# üß™ Test the API\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Test health endpoint\n",
        "try:\n",
        "    response = requests.get(f\"{public_url}/api/v1/codebase/health\")\n",
        "    print(f\"Health Check: {response.json()}\")\n",
        "except Exception as e:\n",
        "    print(f\"Health check failed: {e}\")\n",
        "\n",
        "# Test code generation (requires valid OpenAI API key)\n",
        "test_payload = {\n",
        "    \"prompt\": \"Create a simple hello world function\",\n",
        "    \"language\": \"python\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = requests.post(\n",
        "        f\"{public_url}/api/v1/ai/generate-code\",\n",
        "        json=test_payload,\n",
        "        headers={\"Content-Type\": \"application/json\"}\n",
        "    )\n",
        "    print(f\"\\nCode Generation Test:\")\n",
        "    print(f\"Status: {response.status_code}\")\n",
        "    print(f\"Response: {response.json()}\")\n",
        "except Exception as e:\n",
        "    print(f\"Code generation test failed: {e}\")\n",
        "    print(\"üí° Make sure to update your OpenAI API key in backend/.env\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usage_instructions"
      },
      "source": [
        "## üìñ Usage Instructions\n",
        "\n",
        "### 1. **Setup Your API Key**\n",
        "- Edit `backend/.env` file\n",
        "- Replace `your_openai_api_key_here` with your actual OpenAI API key\n",
        "\n",
        "### 2. **Access Your API**\n",
        "- Use the ngrok URL provided above\n",
        "- Visit `/docs` for interactive API documentation\n",
        "\n",
        "### 3. **Available Endpoints**\n",
        "\n",
        "#### Code Generation\n",
        "```bash\n",
        "curl -X POST \"YOUR_NGROK_URL/api/v1/ai/generate-code\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\"prompt\": \"Create a function to calculate fibonacci\", \"language\": \"python\"}'\n",
        "```\n",
        "\n",
        "#### Code Completion\n",
        "```bash\n",
        "curl -X POST \"YOUR_NGROK_URL/api/v1/ai/suggest-completion\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\"code\": \"def hello_\", \"cursor_position\": 10}'\n",
        "```\n",
        "\n",
        "#### AI Chat\n",
        "```bash\n",
        "curl -X POST \"YOUR_NGROK_URL/api/v1/ai/chat\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\"message\": \"How do I optimize this Python code?\", \"context\": []}'\n",
        "```\n",
        "\n",
        "### 4. **Next Steps**\n",
        "- Check out the training pipeline notebook for custom model development\n",
        "- Explore the hybrid approach for local/cloud integration\n",
        "- Set up the complete development environment\n",
        "\n",
        "### 5. **Persistence**\n",
        "- All files are saved to your Google Drive\n",
        "- Project persists across Colab sessions\n",
        "- Database and logs are maintained\n"
      ]
    }
  ]
}