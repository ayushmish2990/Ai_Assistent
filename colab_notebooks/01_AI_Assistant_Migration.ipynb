{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# 🚀 AI Coding Assistant - Colab Migration\n",
        "\n",
        "This notebook migrates your AI Coding Assistant project to Google Colab environment.\n",
        "\n",
        "## Features:\n",
        "- ✅ Complete project setup in Colab\n",
        "- ✅ FastAPI backend with ngrok tunneling\n",
        "- ✅ AI service integration\n",
        "- ✅ Database setup and management\n",
        "- ✅ File persistence with Google Drive\n",
        "\n",
        "## Prerequisites:\n",
        "1. Enable GPU runtime (Runtime → Change runtime type → GPU)\n",
        "2. Mount Google Drive for persistence\n",
        "3. Have your OpenAI API key ready\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_environment"
      },
      "outputs": [],
      "source": [
        "# 📦 Install Required Packages\n",
        "!pip install fastapi uvicorn[standard] openai python-dotenv\n",
        "!pip install sqlalchemy alembic pydantic[email]\n",
        "!pip install transformers torch datasets\n",
        "!pip install pyngrok\n",
        "\n",
        "# Mount Google Drive for persistence\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Create project directory in Google Drive\n",
        "project_path = '/content/drive/MyDrive/ai-coding-assistant'\n",
        "os.makedirs(project_path, exist_ok=True)\n",
        "os.chdir(project_path)\n",
        "\n",
        "print(f'✅ Working directory: {os.getcwd()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repository"
      },
      "outputs": [],
      "source": [
        "# 📥 Clone or Update Repository\n",
        "\n",
        "# Option 1: Clone from GitHub (if you have a repo)\n",
        "# !git clone https://github.com/yourusername/ai-coding-assistant.git .\n",
        "\n",
        "# Option 2: Create project structure manually\n",
        "import os\n",
        "\n",
        "# Create directory structure\n",
        "directories = [\n",
        "    'backend/app/api/v1',\n",
        "    'backend/app/core',\n",
        "    'backend/app/services',\n",
        "    'backend/app/models',\n",
        "    'backend/app/schemas',\n",
        "    'backend/app/crud',\n",
        "    'backend/app/db',\n",
        "    'data/raw',\n",
        "    'data/processed',\n",
        "    'data/models',\n",
        "    'logs',\n",
        "    'notebooks',\n",
        "    'scripts'\n",
        "]\n",
        "\n",
        "for directory in directories:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    # Create __init__.py files for Python packages\n",
        "    if 'backend/app' in directory:\n",
        "        with open(f'{directory}/__init__.py', 'w') as f:\n",
        "            f.write('')\n",
        "\n",
        "print('✅ Project structure created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_config"
      },
      "outputs": [],
      "source": [
        "# ⚙️ Create Configuration Files\n",
        "\n",
        "# Create .env file\n",
        "env_content = '''\n",
        "# OpenAI Configuration\n",
        "OPENAI_API_KEY=your_openai_api_key_here\n",
        "OPENAI_MODEL=gpt-3.5-turbo\n",
        "\n",
        "# Database Configuration\n",
        "DATABASE_URL=sqlite:///./ai_assistant.db\n",
        "\n",
        "# API Configuration\n",
        "API_V1_STR=/api/v1\n",
        "PROJECT_NAME=AI Coding Assistant\n",
        "\n",
        "# Security\n",
        "SECRET_KEY=your-secret-key-here\n",
        "ACCESS_TOKEN_EXPIRE_MINUTES=30\n",
        "'''\n",
        "\n",
        "with open('backend/.env', 'w') as f:\n",
        "    f.write(env_content.strip())\n",
        "\n",
        "# Create requirements.txt\n",
        "requirements = '''\n",
        "fastapi==0.104.1\n",
        "uvicorn[standard]==0.24.0\n",
        "openai==1.3.0\n",
        "python-dotenv==1.0.0\n",
        "sqlalchemy==2.0.23\n",
        "alembic==1.12.1\n",
        "pydantic[email]==2.5.0\n",
        "python-multipart==0.0.6\n",
        "httpx==0.24.1\n",
        "transformers==4.35.0\n",
        "torch==2.1.0\n",
        "datasets==2.14.0\n",
        "'''\n",
        "\n",
        "with open('backend/requirements.txt', 'w') as f:\n",
        "    f.write(requirements.strip())\n",
        "\n",
        "print('✅ Configuration files created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_backend_core"
      },
      "outputs": [],
      "source": [
        "# 🏗️ Create Backend Core Files\n",
        "\n",
        "# Create config.py\n",
        "config_content = '''\n",
        "from pydantic_settings import BaseSettings\n",
        "from typing import Optional\n",
        "\n",
        "class Settings(BaseSettings):\n",
        "    # OpenAI Settings\n",
        "    OPENAI_API_KEY: str\n",
        "    OPENAI_MODEL: str = \"gpt-3.5-turbo\"\n",
        "    \n",
        "    # Database Settings\n",
        "    DATABASE_URL: str = \"sqlite:///./ai_assistant.db\"\n",
        "    \n",
        "    # API Settings\n",
        "    API_V1_STR: str = \"/api/v1\"\n",
        "    PROJECT_NAME: str = \"AI Coding Assistant\"\n",
        "    \n",
        "    # Security\n",
        "    SECRET_KEY: str\n",
        "    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30\n",
        "    \n",
        "    class Config:\n",
        "        env_file = \".env\"\n",
        "\n",
        "settings = Settings()\n",
        "'''\n",
        "\n",
        "with open('backend/app/core/config.py', 'w') as f:\n",
        "    f.write(config_content.strip())\n",
        "\n",
        "# Create main.py\n",
        "main_content = '''\n",
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from app.api.v1.api import api_router\n",
        "from app.core.config import settings\n",
        "\n",
        "app = FastAPI(\n",
        "    title=settings.PROJECT_NAME,\n",
        "    openapi_url=f\"{settings.API_V1_STR}/openapi.json\"\n",
        ")\n",
        "\n",
        "# Set up CORS\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "app.include_router(api_router, prefix=settings.API_V1_STR)\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"AI Coding Assistant API\", \"status\": \"running\"}\n",
        "'''\n",
        "\n",
        "with open('backend/app/main.py', 'w') as f:\n",
        "    f.write(main_content.strip())\n",
        "\n",
        "print('✅ Backend core files created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_ai_service"
      },
      "outputs": [],
      "source": [
        "# 🤖 Create AI Service\n",
        "\n",
        "ai_service_content = '''\n",
        "import openai\n",
        "from app.core.config import settings\n",
        "from typing import List, Dict, Any\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class AIService:\n",
        "    def __init__(self):\n",
        "        self.client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)\n",
        "        self.model = settings.OPENAI_MODEL\n",
        "        logger.info(f\"AI Service initialized with model: {self.model}\")\n",
        "    \n",
        "    async def generate_code(self, prompt: str, language: str = \"python\") -> str:\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": f\"You are a helpful coding assistant. Generate {language} code based on the user's request.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=1000,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            if \"insufficient_quota\" in str(e) or \"429\" in str(e):\n",
        "                return \"I apologize, but the AI service is currently experiencing quota limitations. Please try again later or check your API key settings.\"\n",
        "            logger.error(f\"Error generating code: {e}\")\n",
        "            return f\"Error generating code: {str(e)}\"\n",
        "    \n",
        "    async def suggest_completion(self, code: str, cursor_position: int) -> str:\n",
        "        try:\n",
        "            prompt = f\"Complete this code:\\n{code}\\n\\nCursor position: {cursor_position}\"\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a code completion assistant. Provide the most likely completion for the given code.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=200,\n",
        "                temperature=0.3\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            if \"insufficient_quota\" in str(e) or \"429\" in str(e):\n",
        "                return \"AI completion temporarily unavailable due to quota limits.\"\n",
        "            logger.error(f\"Error suggesting completion: {e}\")\n",
        "            return f\"Error: {str(e)}\"\n",
        "    \n",
        "    async def chat_with_context(self, message: str, context: List[Dict[str, Any]] = None) -> str:\n",
        "        try:\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI coding assistant. Help users with programming questions, code review, and development tasks.\"}\n",
        "            ]\n",
        "            \n",
        "            if context:\n",
        "                for ctx in context[-5:]:  # Last 5 messages for context\n",
        "                    messages.append(ctx)\n",
        "            \n",
        "            messages.append({\"role\": \"user\", \"content\": message})\n",
        "            \n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=messages,\n",
        "                max_tokens=1500,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            if \"insufficient_quota\" in str(e) or \"429\" in str(e):\n",
        "                return \"I'm currently experiencing quota limitations. Please try again later or consider upgrading your OpenAI plan.\"\n",
        "            logger.error(f\"Error in chat: {e}\")\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "# Global AI service instance\n",
        "ai_service = AIService()\n",
        "'''\n",
        "\n",
        "with open('backend/app/services/ai_service.py', 'w') as f:\n",
        "    f.write(ai_service_content.strip())\n",
        "\n",
        "print('✅ AI service created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_api_routes"
      },
      "outputs": [],
      "source": [
        "# 🛣️ Create API Routes\n",
        "\n",
        "# Create API router\n",
        "api_router_content = '''\n",
        "from fastapi import APIRouter\n",
        "from app.api.v1.endpoints import ai, codebase\n",
        "\n",
        "api_router = APIRouter()\n",
        "api_router.include_router(ai.router, prefix=\"/ai\", tags=[\"ai\"])\n",
        "api_router.include_router(codebase.router, prefix=\"/codebase\", tags=[\"codebase\"])\n",
        "'''\n",
        "\n",
        "os.makedirs('backend/app/api/v1/endpoints', exist_ok=True)\n",
        "with open('backend/app/api/v1/endpoints/__init__.py', 'w') as f:\n",
        "    f.write('')\n",
        "\n",
        "with open('backend/app/api/v1/api.py', 'w') as f:\n",
        "    f.write(api_router_content.strip())\n",
        "\n",
        "# Create AI endpoints\n",
        "ai_endpoints_content = '''\n",
        "from fastapi import APIRouter, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from app.services.ai_service import ai_service\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "router = APIRouter()\n",
        "\n",
        "class CodeGenerationRequest(BaseModel):\n",
        "    prompt: str\n",
        "    language: str = \"python\"\n",
        "\n",
        "class CompletionRequest(BaseModel):\n",
        "    code: str\n",
        "    cursor_position: int\n",
        "\n",
        "class ChatRequest(BaseModel):\n",
        "    message: str\n",
        "    context: Optional[List[Dict[str, Any]]] = None\n",
        "\n",
        "@router.post(\"/generate-code\")\n",
        "async def generate_code(request: CodeGenerationRequest):\n",
        "    try:\n",
        "        result = await ai_service.generate_code(request.prompt, request.language)\n",
        "        return {\"code\": result, \"status\": \"success\"}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@router.post(\"/suggest-completion\")\n",
        "async def suggest_completion(request: CompletionRequest):\n",
        "    try:\n",
        "        result = await ai_service.suggest_completion(request.code, request.cursor_position)\n",
        "        return {\"completion\": result, \"status\": \"success\"}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@router.post(\"/chat\")\n",
        "async def chat(request: ChatRequest):\n",
        "    try:\n",
        "        result = await ai_service.chat_with_context(request.message, request.context)\n",
        "        return {\"response\": result, \"status\": \"success\"}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "'''\n",
        "\n",
        "with open('backend/app/api/v1/endpoints/ai.py', 'w') as f:\n",
        "    f.write(ai_endpoints_content.strip())\n",
        "\n",
        "# Create codebase endpoints\n",
        "codebase_endpoints_content = '''\n",
        "from fastapi import APIRouter\n",
        "\n",
        "router = APIRouter()\n",
        "\n",
        "@router.get(\"/status\")\n",
        "async def get_codebase_status():\n",
        "    return {\"status\": \"active\", \"message\": \"Codebase service is running\"}\n",
        "\n",
        "@router.get(\"/health\")\n",
        "async def health_check():\n",
        "    return {\"status\": \"healthy\", \"service\": \"AI Coding Assistant\"}\n",
        "'''\n",
        "\n",
        "with open('backend/app/api/v1/endpoints/codebase.py', 'w') as f:\n",
        "    f.write(codebase_endpoints_content.strip())\n",
        "\n",
        "print('✅ API routes created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_ngrok"
      },
      "outputs": [],
      "source": [
        "# 🌐 Setup Ngrok for External Access\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import uvicorn\n",
        "import time\n",
        "\n",
        "# Set your ngrok auth token (get it from https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "ngrok.set_auth_token(\"32lxmVvlcVwe0aIQldrGTv9sB0c_2kNsr5fcetExZj6St12dZ\")\n",
        "\n",
        "def start_server():\n",
        "    \"\"\"Start the FastAPI server\"\"\"\n",
        "    os.chdir('backend')\n",
        "    uvicorn.run(\"app.main:app\", host=\"0.0.0.0\", port=8000, reload=False)\n",
        "\n",
        "def setup_ngrok_tunnel():\n",
        "    \"\"\"Setup ngrok tunnel for external access\"\"\"\n",
        "    try:\n",
        "        # Create ngrok tunnel\n",
        "        public_url = ngrok.connect(8000)\n",
        "        print(f\"\\n🌐 Your API is now accessible at: {public_url}\")\n",
        "        print(f\"📋 API Documentation: {public_url}/docs\")\n",
        "        print(f\"🔍 Health Check: {public_url}/api/v1/codebase/health\")\n",
        "        \n",
        "        return public_url\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error setting up ngrok: {e}\")\n",
        "        print(\"💡 You can still access the API locally at: http://localhost:8000\")\n",
        "        return \"http://localhost:8000\"\n",
        "\n",
        "print('✅ Ngrok setup ready')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "start_application"
      },
      "outputs": [],
      "source": [
        "# 🚀 Start the Application\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add backend to Python path\n",
        "backend_path = os.path.join(os.getcwd(), 'backend')\n",
        "if backend_path not in sys.path:\n",
        "    sys.path.insert(0, backend_path)\n",
        "\n",
        "# Update your OpenAI API key in the .env file\n",
        "print(\"⚠️  IMPORTANT: Update your OpenAI API key in backend/.env file\")\n",
        "print(\"📝 Edit the OPENAI_API_KEY value with your actual API key\")\n",
        "\n",
        "# Start the server in a separate thread\n",
        "server_thread = threading.Thread(target=start_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "# Wait for server to start\n",
        "print(\"⏳ Starting server...\")\n",
        "time.sleep(5)\n",
        "\n",
        "# Setup ngrok tunnel\n",
        "public_url = setup_ngrok_tunnel()\n",
        "\n",
        "print(\"\\n✅ AI Coding Assistant is now running!\")\n",
        "print(\"\\n📚 Available endpoints:\")\n",
        "print(f\"  • POST {public_url}/api/v1/ai/generate-code\")\n",
        "print(f\"  • POST {public_url}/api/v1/ai/suggest-completion\")\n",
        "print(f\"  • POST {public_url}/api/v1/ai/chat\")\n",
        "print(f\"  • GET  {public_url}/api/v1/codebase/status\")\n",
        "\n",
        "print(\"\\n🔧 Next steps:\")\n",
        "print(\"1. Update your OpenAI API key in backend/.env\")\n",
        "print(\"2. Test the API using the documentation link above\")\n",
        "print(\"3. Integrate with your frontend application\")\n",
        "print(\"4. Check the training pipeline notebook for custom model development\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_api"
      },
      "outputs": [],
      "source": [
        "# 🧪 Test the API\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Test health endpoint\n",
        "try:\n",
        "    response = requests.get(f\"{public_url}/api/v1/codebase/health\")\n",
        "    print(f\"Health Check: {response.json()}\")\n",
        "except Exception as e:\n",
        "    print(f\"Health check failed: {e}\")\n",
        "\n",
        "# Test code generation (requires valid OpenAI API key)\n",
        "test_payload = {\n",
        "    \"prompt\": \"Create a simple hello world function\",\n",
        "    \"language\": \"python\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = requests.post(\n",
        "        f\"{public_url}/api/v1/ai/generate-code\",\n",
        "        json=test_payload,\n",
        "        headers={\"Content-Type\": \"application/json\"}\n",
        "    )\n",
        "    print(f\"\\nCode Generation Test:\")\n",
        "    print(f\"Status: {response.status_code}\")\n",
        "    print(f\"Response: {response.json()}\")\n",
        "except Exception as e:\n",
        "    print(f\"Code generation test failed: {e}\")\n",
        "    print(\"💡 Make sure to update your OpenAI API key in backend/.env\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usage_instructions"
      },
      "source": [
        "## 📖 Usage Instructions\n",
        "\n",
        "### 1. **Setup Your API Key**\n",
        "- Edit `backend/.env` file\n",
        "- Replace `your_openai_api_key_here` with your actual OpenAI API key\n",
        "\n",
        "### 2. **Access Your API**\n",
        "- Use the ngrok URL provided above\n",
        "- Visit `/docs` for interactive API documentation\n",
        "\n",
        "### 3. **Available Endpoints**\n",
        "\n",
        "#### Code Generation\n",
        "```bash\n",
        "curl -X POST \"YOUR_NGROK_URL/api/v1/ai/generate-code\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\"prompt\": \"Create a function to calculate fibonacci\", \"language\": \"python\"}'\n",
        "```\n",
        "\n",
        "#### Code Completion\n",
        "```bash\n",
        "curl -X POST \"YOUR_NGROK_URL/api/v1/ai/suggest-completion\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\"code\": \"def hello_\", \"cursor_position\": 10}'\n",
        "```\n",
        "\n",
        "#### AI Chat\n",
        "```bash\n",
        "curl -X POST \"YOUR_NGROK_URL/api/v1/ai/chat\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\"message\": \"How do I optimize this Python code?\", \"context\": []}'\n",
        "```\n",
        "\n",
        "### 4. **Next Steps**\n",
        "- Check out the training pipeline notebook for custom model development\n",
        "- Explore the hybrid approach for local/cloud integration\n",
        "- Set up the complete development environment\n",
        "\n",
        "### 5. **Persistence**\n",
        "- All files are saved to your Google Drive\n",
        "- Project persists across Colab sessions\n",
        "- Database and logs are maintained\n"
      ]
    }
  ]
}