{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üöÄ AI Coding Assistant - Colab Migration\n",
        "\n",
        "This notebook migrates your AI Coding Assistant project to Google Colab environment.\n",
        "\n",
        "## Features:\n",
        "- ‚úÖ Complete project setup in Colab\n",
        "- ‚úÖ FastAPI backend with ngrok tunneling\n",
        "- ‚úÖ AI service integration\n",
        "- ‚úÖ Database setup and management\n",
        "- ‚úÖ File persistence with Google Drive\n",
        "\n",
        "## Prerequisites:\n",
        "1. Enable GPU runtime (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
        "2. Mount Google Drive for persistence\n",
        "3. Have your OpenAI API key ready\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_environment"
      },
      "outputs": [],
      "source": [
        "# üì¶ Install Required Packages - Enhanced for Phase 2/3 Capabilities\n",
        "!pip install fastapi uvicorn[standard] openai python-dotenv\n",
        "!pip install sqlalchemy alembic pydantic[email]\n",
        "!pip install transformers torch datasets\n",
        "!pip install pyngrok\n",
        "# Phase 2/3 Enhanced Dependencies\n",
        "!pip install numpy pandas scikit-learn\n",
        "!pip install asyncio aiofiles\n",
        "!pip install jira asana-python\n",
        "!pip install GitPython PyGithub\n",
        "!pip install docker kubernetes\n",
        "!pip install pytest coverage bandit safety\n",
        "!pip install black isort mypy\n",
        "!pip install matplotlib seaborn plotly\n",
        "\n",
        "# Mount Google Drive for persistence\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Create project directory in Google Drive\n",
        "project_path = '/content/drive/MyDrive/ai-coding-assistant'\n",
        "os.makedirs(project_path, exist_ok=True)\n",
        "os.chdir(project_path)\n",
        "\n",
        "print(f'‚úÖ Working directory: {os.getcwd()}')\n",
        "print('üöÄ Enhanced with Phase 2/3 capabilities:')\n",
        "print('  ‚Ä¢ Autonomous Agent System')\n",
        "print('  ‚Ä¢ Reinforcement Learning Engine')\n",
        "print('  ‚Ä¢ Enhanced Project Management')\n",
        "print('  ‚Ä¢ Advanced CI/CD Integration')\n",
        "print('  ‚Ä¢ Main Orchestration System')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repository"
      },
      "outputs": [],
      "source": [
        "# üì• Clone or Update Repository\n",
        "\n",
        "# Option 1: Clone from GitHub (if you have a repo)\n",
        "# !git clone https://github.com/yourusername/ai-coding-assistant.git .\n",
        "\n",
        "# Option 2: Create project structure manually\n",
        "import os\n",
        "\n",
        "# Create directory structure\n",
        "directories = [\n",
        "    'backend/app/api/v1',\n",
        "    'backend/app/core',\n",
        "    'backend/app/services',\n",
        "    'backend/app/models',\n",
        "    'backend/app/schemas',\n",
        "    'backend/app/crud',\n",
        "    'backend/app/db',\n",
        "    # Enhanced Phase 2/3 Core Modules\n",
        "    'src/core',\n",
        "    'src/integrations',\n",
        "    'src/agents',\n",
        "    'src/learning',\n",
        "    'src/orchestration',\n",
        "    'data/raw',\n",
        "    'data/processed',\n",
        "    'data/models',\n",
        "    'data/learning_data',\n",
        "    'logs',\n",
        "    'logs/agent_logs',\n",
        "    'logs/learning_logs',\n",
        "    'notebooks',\n",
        "    'scripts',\n",
        "    'configs/agent_configs',\n",
        "    'configs/integration_configs'\n",
        "]\n",
        "\n",
        "for directory in directories:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    # Create __init__.py files for Python packages\n",
        "    if 'backend/app' in directory or 'src/' in directory:\n",
        "        with open(f'{directory}/__init__.py', 'w') as f:\n",
        "            f.write('')\n",
        "\n",
        "print('‚úÖ Enhanced project structure created with Phase 2/3 capabilities')\n",
        "print('üìÅ New directories:')\n",
        "print('  ‚Ä¢ src/core - Autonomous agent and learning systems')\n",
        "print('  ‚Ä¢ src/integrations - Enhanced project management and CI/CD')\n",
        "print('  ‚Ä¢ src/orchestration - Main orchestration system')\n",
        "print('  ‚Ä¢ data/learning_data - Learning system data storage')\n",
        "print('  ‚Ä¢ logs/agent_logs - Autonomous agent activity logs')\n",
        "print('  ‚Ä¢ configs/agent_configs - Agent configuration files')"
      ]
    },
     {
       "cell_type": "code",
       "execution_count": null,
       "metadata": {
         "id": "create_phase2_3_modules"
       },
       "outputs": [],
       "source": [
         "# üß† Create Phase 2/3 Core Modules\n",
         "\n",
         "# Create autonomous agent system\n",
         "agent_system_content = '''\n",
         "from typing import Dict, List, Any, Optional\n",
         "from dataclasses import dataclass\n",
         "from enum import Enum\n",
         "import asyncio\n",
         "import logging\n",
         "\n",
         "class AgentState(Enum):\n",
         "    IDLE = \"idle\"\n",
         "    PLANNING = \"planning\"\n",
         "    EXECUTING = \"executing\"\n",
         "    LEARNING = \"learning\"\n",
         "    ERROR = \"error\"\n",
         "\n",
         "@dataclass\n",
         "class Task:\n",
         "    id: str\n",
         "    description: str\n",
         "    priority: int\n",
         "    status: str = \"pending\"\n",
         "    result: Optional[Any] = None\n",
         "\n",
         "class AutonomousAgent:\n",
         "    def __init__(self, agent_id: str):\n",
         "        self.agent_id = agent_id\n",
         "        self.state = AgentState.IDLE\n",
         "        self.task_queue: List[Task] = []\n",
         "        self.logger = logging.getLogger(f\"agent_{agent_id}\")\n",
         "    \n",
         "    async def execute_task(self, task: Task) -> Any:\n",
         "        self.state = AgentState.EXECUTING\n",
         "        self.logger.info(f\"Executing task: {task.description}\")\n",
         "        # Task execution logic here\n",
         "        await asyncio.sleep(1)  # Simulate work\n",
         "        task.status = \"completed\"\n",
         "        self.state = AgentState.IDLE\n",
         "        return task\n",
         "    \n",
         "    def add_task(self, task: Task):\n",
         "        self.task_queue.append(task)\n",
         "        self.task_queue.sort(key=lambda t: t.priority, reverse=True)\n",
         "'''\n",
         "\n",
         "with open('src/agents/autonomous_agent.py', 'w') as f:\n",
         "    f.write(agent_system_content.strip())\n",
         "\n",
         "# Create learning system\n",
         "learning_system_content = '''\n",
         "from typing import Dict, List, Any, Optional\n",
         "import numpy as np\n",
         "from dataclasses import dataclass\n",
         "from enum import Enum\n",
         "import json\n",
         "import logging\n",
         "\n",
         "class LearningType(Enum):\n",
         "    REINFORCEMENT = \"reinforcement\"\n",
         "    SUPERVISED = \"supervised\"\n",
         "    UNSUPERVISED = \"unsupervised\"\n",
         "\n",
         "@dataclass\n",
         "class LearningData:\n",
         "    input_data: Any\n",
         "    output_data: Any\n",
         "    reward: float\n",
         "    timestamp: str\n",
         "\n",
         "class ContinuousLearningSystem:\n",
         "    def __init__(self):\n",
         "        self.learning_data: List[LearningData] = []\n",
         "        self.model_weights: Dict[str, Any] = {}\n",
         "        self.logger = logging.getLogger(\"learning_system\")\n",
         "    \n",
         "    def record_interaction(self, data: LearningData):\n",
         "        self.learning_data.append(data)\n",
         "        self.logger.info(f\"Recorded learning data with reward: {data.reward}\")\n",
         "    \n",
         "    def update_model(self, learning_type: LearningType):\n",
         "        self.logger.info(f\"Updating model with {learning_type.value} learning\")\n",
         "        # Model update logic here\n",
         "        pass\n",
         "    \n",
         "    def get_performance_metrics(self) -> Dict[str, float]:\n",
         "        if not self.learning_data:\n",
         "            return {\"average_reward\": 0.0, \"total_interactions\": 0}\n",
         "        \n",
         "        avg_reward = np.mean([d.reward for d in self.learning_data])\n",
         "        return {\n",
         "            \"average_reward\": float(avg_reward),\n",
         "            \"total_interactions\": len(self.learning_data)\n",
         "        }\n",
         "'''\n",
         "\n",
         "with open('src/learning/continuous_learning.py', 'w') as f:\n",
         "    f.write(learning_system_content.strip())\n",
         "\n",
         "# Create orchestration system\n",
         "orchestration_content = '''\n",
         "from typing import Dict, List, Any, Optional\n",
         "import asyncio\n",
         "from dataclasses import dataclass\n",
         "from enum import Enum\n",
         "import logging\n",
         "\n",
         "class SystemState(Enum):\n",
         "    INITIALIZING = \"initializing\"\n",
         "    RUNNING = \"running\"\n",
         "    PAUSED = \"paused\"\n",
         "    ERROR = \"error\"\n",
         "    SHUTDOWN = \"shutdown\"\n",
         "\n",
         "@dataclass\n",
         "class SystemMetrics:\n",
         "    active_agents: int\n",
         "    completed_tasks: int\n",
         "    error_count: int\n",
         "    uptime: float\n",
         "\n",
         "class MainOrchestrator:\n",
         "    def __init__(self):\n",
         "        self.state = SystemState.INITIALIZING\n",
         "        self.agents: Dict[str, Any] = {}\n",
         "        self.integrations: Dict[str, Any] = {}\n",
         "        self.learning_system = None\n",
         "        self.logger = logging.getLogger(\"orchestrator\")\n",
         "    \n",
         "    async def initialize_system(self):\n",
         "        self.logger.info(\"Initializing AI Coding Assistant system...\")\n",
         "        # Initialize all subsystems\n",
         "        self.state = SystemState.RUNNING\n",
         "        self.logger.info(\"System initialization complete\")\n",
         "    \n",
         "    async def coordinate_agents(self):\n",
         "        while self.state == SystemState.RUNNING:\n",
         "            # Agent coordination logic\n",
         "            await asyncio.sleep(1)\n",
         "    \n",
         "    def get_system_status(self) -> Dict[str, Any]:\n",
         "        return {\n",
         "            \"state\": self.state.value,\n",
         "            \"active_agents\": len(self.agents),\n",
         "            \"integrations\": list(self.integrations.keys()),\n",
         "            \"learning_enabled\": self.learning_system is not None\n",
         "        }\n",
         "    \n",
         "    async def shutdown(self):\n",
         "        self.logger.info(\"Shutting down system...\")\n",
         "        self.state = SystemState.SHUTDOWN\n",
         "'''\n",
         "\n",
         "with open('src/orchestration/main_orchestrator.py', 'w') as f:\n",
         "    f.write(orchestration_content.strip())\n",
         "\n",
         "# Create integration manager\n",
         "integration_content = '''\n",
         "from typing import Dict, List, Any, Optional\n",
         "from abc import ABC, abstractmethod\n",
         "import logging\n",
         "\n",
         "class Integration(ABC):\n",
         "    def __init__(self, name: str):\n",
         "        self.name = name\n",
         "        self.is_connected = False\n",
         "        self.logger = logging.getLogger(f\"integration_{name}\")\n",
         "    \n",
         "    @abstractmethod\n",
         "    async def connect(self) -> bool:\n",
         "        pass\n",
         "    \n",
         "    @abstractmethod\n",
         "    async def disconnect(self):\n",
         "        pass\n",
         "\n",
         "class JiraIntegration(Integration):\n",
         "    def __init__(self, server_url: str, username: str, api_token: str):\n",
         "        super().__init__(\"jira\")\n",
         "        self.server_url = server_url\n",
         "        self.username = username\n",
         "        self.api_token = api_token\n",
         "    \n",
         "    async def connect(self) -> bool:\n",
         "        self.logger.info(\"Connecting to Jira...\")\n",
         "        # Jira connection logic\n",
         "        self.is_connected = True\n",
         "        return True\n",
         "    \n",
         "    async def disconnect(self):\n",
         "        self.is_connected = False\n",
         "        self.logger.info(\"Disconnected from Jira\")\n",
         "\n",
         "class GitHubIntegration(Integration):\n",
         "    def __init__(self, token: str):\n",
         "        super().__init__(\"github\")\n",
         "        self.token = token\n",
         "    \n",
         "    async def connect(self) -> bool:\n",
         "        self.logger.info(\"Connecting to GitHub...\")\n",
         "        # GitHub connection logic\n",
         "        self.is_connected = True\n",
         "        return True\n",
         "    \n",
         "    async def disconnect(self):\n",
         "        self.is_connected = False\n",
         "        self.logger.info(\"Disconnected from GitHub\")\n",
         "\n",
         "class IntegrationManager:\n",
         "    def __init__(self):\n",
         "        self.integrations: Dict[str, Integration] = {}\n",
         "        self.logger = logging.getLogger(\"integration_manager\")\n",
         "    \n",
         "    def add_integration(self, integration: Integration):\n",
         "        self.integrations[integration.name] = integration\n",
         "        self.logger.info(f\"Added integration: {integration.name}\")\n",
         "    \n",
         "    async def connect_all(self):\n",
         "        for name, integration in self.integrations.items():\n",
         "            try:\n",
         "                await integration.connect()\n",
         "                self.logger.info(f\"Successfully connected to {name}\")\n",
         "            except Exception as e:\n",
         "                self.logger.error(f\"Failed to connect to {name}: {e}\")\n",
         "'''\n",
         "\n",
         "with open('src/integrations/integration_manager.py', 'w') as f:\n",
         "    f.write(integration_content.strip())\n",
         "\n",
         "print('‚úÖ Phase 2/3 core modules created:')\n",
         "print('  ‚Ä¢ Autonomous Agent System')\n",
         "print('  ‚Ä¢ Continuous Learning System')\n",
         "print('  ‚Ä¢ Main Orchestration System')\n",
         "print('  ‚Ä¢ Integration Manager (Jira, GitHub, etc.)')\n",
         "print('üöÄ Enhanced AI Coding Assistant ready for deployment!')"
       ]
     },
     {
       "cell_type": "code",
       "execution_count": null,
       "metadata": {
         "id": "create_config"
       },
       "outputs": [],
       "source": [
        "# ‚öôÔ∏è Create Configuration Files\n",
        "\n",
        "# Create .env file\n",
        "env_content = '''\n",
        "# OpenAI Configuration\n",
        "OPENAI_API_KEY=your_openai_api_key_here\n",
        "OPENAI_MODEL=gpt-3.5-turbo\n",
        "\n",
        "# Database Configuration\n",
        "DATABASE_URL=sqlite:///./ai_assistant.db\n",
        "\n",
        "# API Configuration\n",
        "API_V1_STR=/api/v1\n",
        "PROJECT_NAME=AI Coding Assistant\n",
        "\n",
        "# Security\n",
        "SECRET_KEY=your-secret-key-here\n",
        "ACCESS_TOKEN_EXPIRE_MINUTES=30\n",
        "'''\n",
        "\n",
        "with open('backend/.env', 'w') as f:\n",
        "    f.write(env_content.strip())\n",
        "\n",
        "# Create requirements.txt\n",
        "requirements = '''\n",
        "fastapi==0.104.1\n",
        "uvicorn[standard]==0.24.0\n",
        "openai==1.3.0\n",
        "python-dotenv==1.0.0\n",
        "sqlalchemy==2.0.23\n",
        "alembic==1.12.1\n",
        "pydantic[email]==2.5.0\n",
        "python-multipart==0.0.6\n",
        "httpx==0.24.1\n",
        "transformers==4.35.0\n",
        "torch==2.1.0\n",
        "datasets==2.14.0\n",
        "'''\n",
        "\n",
        "with open('backend/requirements.txt', 'w') as f:\n",
        "    f.write(requirements.strip())\n",
        "\n",
        "print('‚úÖ Configuration files created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_backend_core"
      },
      "outputs": [],
      "source": [
        "# üèóÔ∏è Create Backend Core Files\n",
        "\n",
        "# Create config.py\n",
        "config_content = '''\n",
        "from pydantic_settings import BaseSettings\n",
        "from typing import Optional\n",
        "\n",
        "class Settings(BaseSettings):\n",
        "    # OpenAI Settings\n",
        "    OPENAI_API_KEY: str\n",
        "    OPENAI_MODEL: str = \"gpt-3.5-turbo\"\n",
        "    \n",
        "    # Database Settings\n",
        "    DATABASE_URL: str = \"sqlite:///./ai_assistant.db\"\n",
        "    \n",
        "    # API Settings\n",
        "    API_V1_STR: str = \"/api/v1\"\n",
        "    PROJECT_NAME: str = \"AI Coding Assistant\"\n",
        "    \n",
        "    # Security\n",
        "    SECRET_KEY: str\n",
        "    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30\n",
        "    \n",
        "    class Config:\n",
        "        env_file = \".env\"\n",
        "\n",
        "settings = Settings()\n",
        "'''\n",
        "\n",
        "with open('backend/app/core/config.py', 'w') as f:\n",
        "    f.write(config_content.strip())\n",
        "\n",
        "# Create main.py\n",
        "main_content = '''\n",
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from app.api.v1.api import api_router\n",
        "from app.core.config import settings\n",
        "\n",
        "app = FastAPI(\n",
        "    title=settings.PROJECT_NAME,\n",
        "    openapi_url=f\"{settings.API_V1_STR}/openapi.json\"\n",
        ")\n",
        "\n",
        "# Set up CORS\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "app.include_router(api_router, prefix=settings.API_V1_STR)\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"AI Coding Assistant API\", \"status\": \"running\"}\n",
        "'''\n",
        "\n",
        "with open('backend/app/main.py', 'w') as f:\n",
        "    f.write(main_content.strip())\n",
        "\n",
        "print('‚úÖ Backend core files created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_ai_service"
      },
      "outputs": [],
      "source": [
        "# ü§ñ Create AI Service\n",
        "\n",
        "ai_service_content = '''\n",
        "import openai\n",
        "from app.core.config import settings\n",
        "from typing import List, Dict, Any\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class AIService:\n",
        "    def __init__(self):\n",
        "        self.client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)\n",
        "        self.model = settings.OPENAI_MODEL\n",
        "        logger.info(f\"AI Service initialized with model: {self.model}\")\n",
        "    \n",
        "    async def generate_code(self, prompt: str, language: str = \"python\") -> str:\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": f\"You are a helpful coding assistant. Generate {language} code based on the user's request.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=1000,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            if \"insufficient_quota\" in str(e) or \"429\" in str(e):\n",
        "                return \"I apologize, but the AI service is currently experiencing quota limitations. Please try again later or check your API key settings.\"\n",
        "            logger.error(f\"Error generating code: {e}\")\n",
        "            return f\"Error generating code: {str(e)}\"\n",
        "    \n",
        "    async def suggest_completion(self, code: str, cursor_position: int) -> str:\n",
        "        try:\n",
        "            prompt = f\"Complete this code:\\n{code}\\n\\nCursor position: {cursor_position}\"\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a code completion assistant. Provide the most likely completion for the given code.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=200,\n",
        "                temperature=0.3\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            if \"insufficient_quota\" in str(e) or \"429\" in str(e):\n",
        "                return \"AI completion temporarily unavailable due to quota limits.\"\n",
        "            logger.error(f\"Error suggesting completion: {e}\")\n",
        "            return f\"Error: {str(e)}\"\n",
        "    \n",
        "    async def chat_with_context(self, message: str, context: List[Dict[str, Any]] = None) -> str:\n",
        "        try:\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI coding assistant. Help users with programming questions, code review, and development tasks.\"}\n",
        "            ]\n",
        "            \n",
        "            if context:\n",
        "                for ctx in context[-5:]:  # Last 5 messages for context\n",
        "                    messages.append(ctx)\n",
        "            \n",
        "            messages.append({\"role\": \"user\", \"content\": message})\n",
        "            \n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=messages,\n",
        "                max_tokens=1500,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            if \"insufficient_quota\" in str(e) or \"429\" in str(e):\n",
        "                return \"I'm currently experiencing quota limitations. Please try again later or consider upgrading your OpenAI plan.\"\n",
        "            logger.error(f\"Error in chat: {e}\")\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "# Global AI service instance\n",
        "ai_service = AIService()\n",
        "'''\n",
        "\n",
        "with open('backend/app/services/ai_service.py', 'w') as f:\n",
        "    f.write(ai_service_content.strip())\n",
        "\n",
        "print('‚úÖ AI service created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_api_routes"
      },
      "outputs": [],
      "source": [
        "# üõ£Ô∏è Create API Routes\n",
        "\n",
        "# Create API router\n",
        "api_router_content = '''\n",
        "from fastapi import APIRouter\n",
        "from app.api.v1.endpoints import ai, codebase\n",
        "\n",
        "api_router = APIRouter()\n",
        "api_router.include_router(ai.router, prefix=\"/ai\", tags=[\"ai\"])\n",
        "api_router.include_router(codebase.router, prefix=\"/codebase\", tags=[\"codebase\"])\n",
        "'''\n",
        "\n",
        "os.makedirs('backend/app/api/v1/endpoints', exist_ok=True)\n",
        "with open('backend/app/api/v1/endpoints/__init__.py', 'w') as f:\n",
        "    f.write('')\n",
        "\n",
        "with open('backend/app/api/v1/api.py', 'w') as f:\n",
        "    f.write(api_router_content.strip())\n",
        "\n",
        "# Create AI endpoints\n",
        "ai_endpoints_content = '''\n",
        "from fastapi import APIRouter, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from app.services.ai_service import ai_service\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "router = APIRouter()\n",
        "\n",
        "class CodeGenerationRequest(BaseModel):\n",
        "    prompt: str\n",
        "    language: str = \"python\"\n",
        "\n",
        "class CompletionRequest(BaseModel):\n",
        "    code: str\n",
        "    cursor_position: int\n",
        "\n",
        "class ChatRequest(BaseModel):\n",
        "    message: str\n",
        "    context: Optional[List[Dict[str, Any]]] = None\n",
        "\n",
        "@router.post(\"/generate-code\")\n",
        "async def generate_code(request: CodeGenerationRequest):\n",
        "    try:\n",
        "        result = await ai_service.generate_code(request.prompt, request.language)\n",
        "        return {\"code\": result, \"status\": \"success\"}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@router.post(\"/suggest-completion\")\n",
        "async def suggest_completion(request: CompletionRequest):\n",
        "    try:\n",
        "        result = await ai_service.suggest_completion(request.code, request.cursor_position)\n",
        "        return {\"completion\": result, \"status\": \"success\"}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@router.post(\"/chat\")\n",
        "async def chat(request: ChatRequest):\n",
        "    try:\n",
        "        result = await ai_service.chat_with_context(request.message, request.context)\n",
        "        return {\"response\": result, \"status\": \"success\"}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "'''\n",
        "\n",
        "with open('backend/app/api/v1/endpoints/ai.py', 'w') as f:\n",
        "    f.write(ai_endpoints_content.strip())\n",
        "\n",
        "# Create codebase endpoints\n",
        "codebase_endpoints_content = '''\n",
        "from fastapi import APIRouter\n",
        "\n",
        "router = APIRouter()\n",
        "\n",
        "@router.get(\"/status\")\n",
        "async def get_codebase_status():\n",
        "    return {\"status\": \"active\", \"message\": \"Codebase service is running\"}\n",
        "\n",
        "@router.get(\"/health\")\n",
        "async def health_check():\n",
        "    return {\"status\": \"healthy\", \"service\": \"AI Coding Assistant\"}\n",
        "'''\n",
        "\n",
        "with open('backend/app/api/v1/endpoints/codebase.py', 'w') as f:\n",
        "    f.write(codebase_endpoints_content.strip())\n",
        "\n",
        "print('‚úÖ API routes created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_ngrok"
      },
      "outputs": [],
      "source": [
        "# üåê Setup Ngrok for External Access\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import uvicorn\n",
        "import time\n",
        "\n",
        "# Set your ngrok auth token (get it from https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "ngrok.set_auth_token(\"32lxmVvlcVwe0aIQldrGTv9sB0c_2kNsr5fcetExZj6St12dZ\")\n",
        "\n",
        "def start_server():\n",
        "    \"\"\"Start the FastAPI server\"\"\"\n",
        "    os.chdir('backend')\n",
        "    uvicorn.run(\"app.main:app\", host=\"0.0.0.0\", port=8000, reload=False)\n",
        "\n",
        "def setup_ngrok_tunnel():\n",
        "    \"\"\"Setup ngrok tunnel for external access\"\"\"\n",
        "    try:\n",
        "        # Create ngrok tunnel\n",
        "        public_url = ngrok.connect(8000)\n",
        "        print(f\"\\nüåê Your API is now accessible at: {public_url}\")\n",
        "        print(f\"üìã API Documentation: {public_url}/docs\")\n",
        "        print(f\"üîç Health Check: {public_url}/api/v1/codebase/health\")\n",
        "        \n",
        "        return public_url\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error setting up ngrok: {e}\")\n",
        "        print(\"üí° You can still access the API locally at: http://localhost:8000\")\n",
        "        return \"http://localhost:8000\"\n",
        "\n",
        "print('‚úÖ Ngrok setup ready')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "start_application"
      },
      "outputs": [],
      "source": [
        "# üöÄ Start the Application\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add backend to Python path\n",
        "backend_path = os.path.join(os.getcwd(), 'backend')\n",
        "if backend_path not in sys.path:\n",
        "    sys.path.insert(0, backend_path)\n",
        "\n",
        "# Update your OpenAI API key in the .env file\n",
        "print(\"‚ö†Ô∏è  IMPORTANT: Update your OpenAI API key in backend/.env file\")\n",
        "print(\"üìù Edit the OPENAI_API_KEY value with your actual API key\")\n",
        "\n",
        "# Start the server in a separate thread\n",
        "server_thread = threading.Thread(target=start_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "# Wait for server to start\n",
        "print(\"‚è≥ Starting server...\")\n",
        "time.sleep(5)\n",
        "\n",
        "# Setup ngrok tunnel\n",
        "public_url = setup_ngrok_tunnel()\n",
        "\n",
        "print(\"\\n‚úÖ AI Coding Assistant is now running!\")\n",
        "print(\"\\nüìö Available endpoints:\")\n",
        "print(f\"  ‚Ä¢ POST {public_url}/api/v1/ai/generate-code\")\n",
        "print(f\"  ‚Ä¢ POST {public_url}/api/v1/ai/suggest-completion\")\n",
        "print(f\"  ‚Ä¢ POST {public_url}/api/v1/ai/chat\")\n",
        "print(f\"  ‚Ä¢ GET  {public_url}/api/v1/codebase/status\")\n",
        "\n",
        "print(\"\\nüîß Next steps:\")\n",
        "print(\"1. Update your OpenAI API key in backend/.env\")\n",
        "print(\"2. Test the API using the documentation link above\")\n",
        "print(\"3. Integrate with your frontend application\")\n",
        "print(\"4. Check the training pipeline notebook for custom model development\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_api"
      },
      "outputs": [],
      "source": [
        "# üß™ Test the API\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Test health endpoint\n",
        "try:\n",
        "    response = requests.get(f\"{public_url}/api/v1/codebase/health\")\n",
        "    print(f\"Health Check: {response.json()}\")\n",
        "except Exception as e:\n",
        "    print(f\"Health check failed: {e}\")\n",
        "\n",
        "# Test code generation (requires valid OpenAI API key)\n",
        "test_payload = {\n",
        "    \"prompt\": \"Create a simple hello world function\",\n",
        "    \"language\": \"python\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = requests.post(\n",
        "        f\"{public_url}/api/v1/ai/generate-code\",\n",
        "        json=test_payload,\n",
        "        headers={\"Content-Type\": \"application/json\"}\n",
        "    )\n",
        "    print(f\"\\nCode Generation Test:\")\n",
        "    print(f\"Status: {response.status_code}\")\n",
        "    print(f\"Response: {response.json()}\")\n",
        "except Exception as e:\n",
        "    print(f\"Code generation test failed: {e}\")\n",
        "    print(\"üí° Make sure to update your OpenAI API key in backend/.env\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usage_instructions"
      },
      "source": [
        "## üìñ Usage Instructions\n",
        "\n",
        "### 1. **Setup Your API Key**\n",
        "- Edit `backend/.env` file\n",
        "- Replace `your_openai_api_key_here` with your actual OpenAI API key\n",
        "\n",
        "### 2. **Access Your API**\n",
        "- Use the ngrok URL provided above\n",
        "- Visit `/docs` for interactive API documentation\n",
        "\n",
        "### 3. **Available Endpoints**\n",
        "\n",
        "#### Code Generation\n",
        "```bash\n",
        "curl -X POST \"YOUR_NGROK_URL/api/v1/ai/generate-code\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\"prompt\": \"Create a function to calculate fibonacci\", \"language\": \"python\"}'\n",
        "```\n",
        "\n",
        "#### Code Completion\n",
        "```bash\n",
        "curl -X POST \"YOUR_NGROK_URL/api/v1/ai/suggest-completion\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\"code\": \"def hello_\", \"cursor_position\": 10}'\n",
        "```\n",
        "\n",
        "#### AI Chat\n",
        "```bash\n",
        "curl -X POST \"YOUR_NGROK_URL/api/v1/ai/chat\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\"message\": \"How do I optimize this Python code?\", \"context\": []}'\n",
        "```\n",
        "\n",
        "### 4. **Next Steps**\n",
        "- Check out the training pipeline notebook for custom model development\n",
        "- Explore the hybrid approach for local/cloud integration\n",
        "- Set up the complete development environment\n",
        "\n",
        "### 5. **Persistence**\n",
        "- All files are saved to your Google Drive\n",
        "- Project persists across Colab sessions\n",
        "- Database and logs are maintained\n"
      ]
    }
  ]
}