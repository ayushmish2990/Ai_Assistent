{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkXxX9TyNkXxX9TyNk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phase2_monitoring_system"
      },
      "outputs": [],
      "source": [
        "# 🤖 Phase 2/3 Advanced Monitoring System\n",
        "\n",
        "class Phase2MonitoringSystem:\n",
        "    \"\"\"Advanced monitoring system for Phase 2/3 capabilities\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.metrics_history = defaultdict(deque)\n",
        "        self.agent_metrics = {}\n",
        "        self.workflow_metrics = {}\n",
        "        self.learning_metrics = {}\n",
        "        self.start_time = datetime.now()\n",
        "        self.max_history_size = 1000\n",
        "    \n",
        "    def track_agent_performance(self, agent_id: str, metrics: Dict[str, Any]):\n",
        "        \"\"\"Track autonomous agent performance metrics\"\"\"\n",
        "        timestamp = datetime.now()\n",
        "        \n",
        "        if agent_id not in self.agent_metrics:\n",
        "            self.agent_metrics[agent_id] = {\n",
        "                'total_tasks': 0,\n",
        "                'successful_tasks': 0,\n",
        "                'failed_tasks': 0,\n",
        "                'average_execution_time': 0,\n",
        "                'last_activity': timestamp,\n",
        "                'performance_history': deque(maxlen=self.max_history_size)\n",
        "            }\n",
        "        \n",
        "        agent_data = self.agent_metrics[agent_id]\n",
        "        agent_data['total_tasks'] += 1\n",
        "        agent_data['last_activity'] = timestamp\n",
        "        \n",
        "        if metrics.get('status') == 'success':\n",
        "            agent_data['successful_tasks'] += 1\n",
        "        else:\n",
        "            agent_data['failed_tasks'] += 1\n",
        "        \n",
        "        # Update average execution time\n",
        "        if 'execution_time' in metrics:\n",
        "            current_avg = agent_data['average_execution_time']\n",
        "            total_tasks = agent_data['total_tasks']\n",
        "            new_avg = (current_avg * (total_tasks - 1) + metrics['execution_time']) / total_tasks\n",
        "            agent_data['average_execution_time'] = new_avg\n",
        "        \n",
        "        # Store detailed metrics\n",
        "        agent_data['performance_history'].append({\n",
        "            'timestamp': timestamp,\n",
        "            'metrics': metrics\n",
        "        })\n",
        "    \n",
        "    def track_workflow_execution(self, workflow_id: str, execution_data: Dict[str, Any]):\n",
        "        \"\"\"Track workflow execution metrics\"\"\"\n",
        "        timestamp = datetime.now()\n",
        "        \n",
        "        if workflow_id not in self.workflow_metrics:\n",
        "            self.workflow_metrics[workflow_id] = {\n",
        "                'total_executions': 0,\n",
        "                'successful_executions': 0,\n",
        "                'failed_executions': 0,\n",
        "                'average_duration': 0,\n",
        "                'execution_history': deque(maxlen=self.max_history_size)\n",
        "            }\n",
        "        \n",
        "        workflow_data = self.workflow_metrics[workflow_id]\n",
        "        workflow_data['total_executions'] += 1\n",
        "        \n",
        "        if execution_data.get('status') == 'completed':\n",
        "            workflow_data['successful_executions'] += 1\n",
        "        else:\n",
        "            workflow_data['failed_executions'] += 1\n",
        "        \n",
        "        # Update average duration\n",
        "        if 'duration' in execution_data:\n",
        "            current_avg = workflow_data['average_duration']\n",
        "            total_executions = workflow_data['total_executions']\n",
        "            new_avg = (current_avg * (total_executions - 1) + execution_data['duration']) / total_executions\n",
        "            workflow_data['average_duration'] = new_avg\n",
        "        \n",
        "        workflow_data['execution_history'].append({\n",
        "            'timestamp': timestamp,\n",
        "            'data': execution_data\n",
        "        })\n",
        "    \n",
        "    def track_learning_progress(self, learning_data: Dict[str, Any]):\n",
        "        \"\"\"Track learning system progress and performance\"\"\"\n",
        "        timestamp = datetime.now()\n",
        "        \n",
        "        # Initialize learning metrics if not exists\n",
        "        if not self.learning_metrics:\n",
        "            self.learning_metrics = {\n",
        "                'total_learning_episodes': 0,\n",
        "                'average_reward': 0,\n",
        "                'learning_rate_history': deque(maxlen=self.max_history_size),\n",
        "                'reward_history': deque(maxlen=self.max_history_size),\n",
        "                'performance_improvements': 0\n",
        "            }\n",
        "        \n",
        "        self.learning_metrics['total_learning_episodes'] += 1\n",
        "        \n",
        "        if 'reward' in learning_data:\n",
        "            reward = learning_data['reward']\n",
        "            current_avg = self.learning_metrics['average_reward']\n",
        "            total_episodes = self.learning_metrics['total_learning_episodes']\n",
        "            new_avg = (current_avg * (total_episodes - 1) + reward) / total_episodes\n",
        "            self.learning_metrics['average_reward'] = new_avg\n",
        "            \n",
        "            self.learning_metrics['reward_history'].append({\n",
        "                'timestamp': timestamp,\n",
        "                'reward': reward\n",
        "            })\n",
        "        \n",
        "        if 'learning_rate' in learning_data:\n",
        "            self.learning_metrics['learning_rate_history'].append({\n",
        "                'timestamp': timestamp,\n",
        "                'learning_rate': learning_data['learning_rate']\n",
        "            })\n",
        "    \n",
        "    def generate_performance_report(self) -> Dict[str, Any]:\n",
        "        \"\"\"Generate comprehensive performance report\"\"\"\n",
        "        uptime = datetime.now() - self.start_time\n",
        "        \n",
        "        report = {\n",
        "            'system_uptime': str(uptime),\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'agent_summary': {\n",
        "                'total_agents': len(self.agent_metrics),\n",
        "                'active_agents': sum(1 for agent in self.agent_metrics.values() \n",
        "                                   if (datetime.now() - agent['last_activity']).seconds < 300),\n",
        "                'total_tasks_executed': sum(agent['total_tasks'] for agent in self.agent_metrics.values()),\n",
        "                'overall_success_rate': self._calculate_overall_success_rate()\n",
        "            },\n",
        "            'workflow_summary': {\n",
        "                'total_workflows': len(self.workflow_metrics),\n",
        "                'total_executions': sum(wf['total_executions'] for wf in self.workflow_metrics.values()),\n",
        "                'workflow_success_rate': self._calculate_workflow_success_rate()\n",
        "            },\n",
        "            'learning_summary': {\n",
        "                'total_episodes': self.learning_metrics.get('total_learning_episodes', 0),\n",
        "                'average_reward': self.learning_metrics.get('average_reward', 0),\n",
        "                'learning_trend': self._calculate_learning_trend()\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        return report\n",
        "    \n",
        "    def _calculate_overall_success_rate(self) -> float:\n",
        "        \"\"\"Calculate overall agent success rate\"\"\"\n",
        "        if not self.agent_metrics:\n",
        "            return 0.0\n",
        "        \n",
        "        total_tasks = sum(agent['total_tasks'] for agent in self.agent_metrics.values())\n",
        "        successful_tasks = sum(agent['successful_tasks'] for agent in self.agent_metrics.values())\n",
        "        \n",
        "        return (successful_tasks / total_tasks * 100) if total_tasks > 0 else 0.0\n",
        "    \n",
        "    def _calculate_workflow_success_rate(self) -> float:\n",
        "        \"\"\"Calculate overall workflow success rate\"\"\"\n",
        "        if not self.workflow_metrics:\n",
        "            return 0.0\n",
        "        \n",
        "        total_executions = sum(wf['total_executions'] for wf in self.workflow_metrics.values())\n",
        "        successful_executions = sum(wf['successful_executions'] for wf in self.workflow_metrics.values())\n",
        "        \n",
        "        return (successful_executions / total_executions * 100) if total_executions > 0 else 0.0\n",
        "    \n",
        "    def _calculate_learning_trend(self) -> str:\n",
        "        \"\"\"Calculate learning performance trend\"\"\"\n",
        "        reward_history = self.learning_metrics.get('reward_history', [])\n",
        "        \n",
        "        if len(reward_history) < 10:\n",
        "            return \"insufficient_data\"\n",
        "        \n",
        "        recent_rewards = [entry['reward'] for entry in list(reward_history)[-10:]]\n",
        "        older_rewards = [entry['reward'] for entry in list(reward_history)[-20:-10]] if len(reward_history) >= 20 else []\n",
        "        \n",
        "        if not older_rewards:\n",
        "            return \"insufficient_data\"\n",
        "        \n",
        "        recent_avg = sum(recent_rewards) / len(recent_rewards)\n",
        "        older_avg = sum(older_rewards) / len(older_rewards)\n",
        "        \n",
        "        if recent_avg > older_avg * 1.05:\n",
        "            return \"improving\"\n",
        "        elif recent_avg < older_avg * 0.95:\n",
        "            return \"declining\"\n",
        "        else:\n",
        "            return \"stable\"\n",
        "\n",
        "# Initialize monitoring system\n",
        "phase2_monitor = Phase2MonitoringSystem()\n",
        "print('🤖 Phase 2/3 Monitoring System initialized!')\n",
        "print('📊 Ready to track agents, workflows, and learning progress!')"
      ]
    },
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phase2_visualization_dashboard"
      },
      "outputs": [],
      "source": [
        "# 📊 Phase 2/3 Visualization Dashboard\n",
        "\n",
        "class Phase2VisualizationDashboard:\n",
        "    \"\"\"Advanced visualization dashboard for Phase 2/3 monitoring\"\"\"\n",
        "    \n",
        "    def __init__(self, monitoring_system: Phase2MonitoringSystem):\n",
        "        self.monitor = monitoring_system\n",
        "        plt.style.use('seaborn-v0_8')\n",
        "        sns.set_palette(\"husl\")\n",
        "    \n",
        "    def create_agent_performance_chart(self, agent_id: str = None):\n",
        "        \"\"\"Create agent performance visualization\"\"\"\n",
        "        if agent_id and agent_id in self.monitor.agent_metrics:\n",
        "            # Single agent performance\n",
        "            agent_data = self.monitor.agent_metrics[agent_id]\n",
        "            \n",
        "            fig = go.Figure()\n",
        "            \n",
        "            # Success rate over time\n",
        "            history = list(agent_data['performance_history'])\n",
        "            timestamps = [entry['timestamp'] for entry in history]\n",
        "            success_rates = []\n",
        "            \n",
        "            running_success = 0\n",
        "            running_total = 0\n",
        "            \n",
        "            for entry in history:\n",
        "                running_total += 1\n",
        "                if entry['metrics'].get('status') == 'success':\n",
        "                    running_success += 1\n",
        "                success_rates.append((running_success / running_total) * 100)\n",
        "            \n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=timestamps,\n",
        "                y=success_rates,\n",
        "                mode='lines+markers',\n",
        "                name=f'Agent {agent_id} Success Rate',\n",
        "                line=dict(width=2)\n",
        "            ))\n",
        "            \n",
        "            fig.update_layout(\n",
        "                title=f'Agent {agent_id} Performance Over Time',\n",
        "                xaxis_title='Time',\n",
        "                yaxis_title='Success Rate (%)',\n",
        "                hovermode='x unified'\n",
        "            )\n",
        "            \n",
        "            fig.show()\n",
        "        \n",
        "        else:\n",
        "            # All agents overview\n",
        "            if not self.monitor.agent_metrics:\n",
        "                print('No agent data available for visualization')\n",
        "                return\n",
        "            \n",
        "            agents = list(self.monitor.agent_metrics.keys())\n",
        "            success_rates = []\n",
        "            total_tasks = []\n",
        "            avg_execution_times = []\n",
        "            \n",
        "            for agent_id in agents:\n",
        "                agent_data = self.monitor.agent_metrics[agent_id]\n",
        "                total = agent_data['total_tasks']\n",
        "                successful = agent_data['successful_tasks']\n",
        "                success_rate = (successful / total * 100) if total > 0 else 0\n",
        "                \n",
        "                success_rates.append(success_rate)\n",
        "                total_tasks.append(total)\n",
        "                avg_execution_times.append(agent_data['average_execution_time'])\n",
        "            \n",
        "            # Create subplots\n",
        "            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "            \n",
        "            # Success rates bar chart\n",
        "            ax1.bar(agents, success_rates, color='skyblue')\n",
        "            ax1.set_title('Agent Success Rates')\n",
        "            ax1.set_ylabel('Success Rate (%)')\n",
        "            ax1.tick_params(axis='x', rotation=45)\n",
        "            \n",
        "            # Total tasks bar chart\n",
        "            ax2.bar(agents, total_tasks, color='lightgreen')\n",
        "            ax2.set_title('Total Tasks Executed')\n",
        "            ax2.set_ylabel('Number of Tasks')\n",
        "            ax2.tick_params(axis='x', rotation=45)\n",
        "            \n",
        "            # Average execution time\n",
        "            ax3.bar(agents, avg_execution_times, color='salmon')\n",
        "            ax3.set_title('Average Execution Time')\n",
        "            ax3.set_ylabel('Time (seconds)')\n",
        "            ax3.tick_params(axis='x', rotation=45)\n",
        "            \n",
        "            # Agent status pie chart\n",
        "            active_agents = sum(1 for agent in self.monitor.agent_metrics.values() \n",
        "                              if (datetime.now() - agent['last_activity']).seconds < 300)\n",
        "            inactive_agents = len(agents) - active_agents\n",
        "            \n",
        "            ax4.pie([active_agents, inactive_agents], \n",
        "                   labels=['Active', 'Inactive'], \n",
        "                   autopct='%1.1f%%',\n",
        "                   colors=['lightblue', 'lightcoral'])\n",
        "            ax4.set_title('Agent Status Distribution')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "    \n",
        "    def create_learning_progress_chart(self):\n",
        "        \"\"\"Create learning system progress visualization\"\"\"\n",
        "        if not self.monitor.learning_metrics.get('reward_history'):\n",
        "            print('No learning data available for visualization')\n",
        "            return\n",
        "        \n",
        "        reward_history = list(self.monitor.learning_metrics['reward_history'])\n",
        "        timestamps = [entry['timestamp'] for entry in reward_history]\n",
        "        rewards = [entry['reward'] for entry in reward_history]\n",
        "        \n",
        "        # Calculate moving average\n",
        "        window_size = min(10, len(rewards))\n",
        "        moving_avg = pd.Series(rewards).rolling(window=window_size).mean()\n",
        "        \n",
        "        fig = go.Figure()\n",
        "        \n",
        "        # Raw rewards\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=timestamps,\n",
        "            y=rewards,\n",
        "            mode='markers',\n",
        "            name='Individual Rewards',\n",
        "            opacity=0.6,\n",
        "            marker=dict(size=4)\n",
        "        ))\n",
        "        \n",
        "        # Moving average\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=timestamps,\n",
        "            y=moving_avg,\n",
        "            mode='lines',\n",
        "            name=f'Moving Average ({window_size} episodes)',\n",
        "            line=dict(width=3, color='red')\n",
        "        ))\n",
        "        \n",
        "        fig.update_layout(\n",
        "            title='Learning System Progress',\n",
        "            xaxis_title='Time',\n",
        "            yaxis_title='Reward',\n",
        "            hovermode='x unified'\n",
        "        )\n",
        "        \n",
        "        fig.show()\n",
        "    \n",
        "    def create_workflow_execution_chart(self):\n",
        "        \"\"\"Create workflow execution visualization\"\"\"\n",
        "        if not self.monitor.workflow_metrics:\n",
        "            print('No workflow data available for visualization')\n",
        "            return\n",
        "        \n",
        "        workflows = list(self.monitor.workflow_metrics.keys())\n",
        "        success_rates = []\n",
        "        total_executions = []\n",
        "        avg_durations = []\n",
        "        \n",
        "        for workflow_id in workflows:\n",
        "            workflow_data = self.monitor.workflow_metrics[workflow_id]\n",
        "            total = workflow_data['total_executions']\n",
        "            successful = workflow_data['successful_executions']\n",
        "            success_rate = (successful / total * 100) if total > 0 else 0\n",
        "            \n",
        "            success_rates.append(success_rate)\n",
        "            total_executions.append(total)\n",
        "            avg_durations.append(workflow_data['average_duration'])\n",
        "        \n",
        "        # Create interactive plotly chart\n",
        "        fig = go.Figure()\n",
        "        \n",
        "        # Bubble chart: x=success_rate, y=avg_duration, size=total_executions\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=success_rates,\n",
        "            y=avg_durations,\n",
        "            mode='markers+text',\n",
        "            marker=dict(\n",
        "                size=[max(10, min(50, exec_count * 2)) for exec_count in total_executions],\n",
        "                color=success_rates,\n",
        "                colorscale='Viridis',\n",
        "                showscale=True,\n",
        "                colorbar=dict(title='Success Rate (%)')\n",
        "            ),\n",
        "            text=workflows,\n",
        "            textposition='middle center',\n",
        "            hovertemplate='<b>%{text}</b><br>' +\n",
        "                         'Success Rate: %{x:.1f}%<br>' +\n",
        "                         'Avg Duration: %{y:.2f}s<br>' +\n",
        "                         'Total Executions: %{marker.size}<extra></extra>'\n",
        "        ))\n",
        "        \n",
        "        fig.update_layout(\n",
        "            title='Workflow Performance Overview',\n",
        "            xaxis_title='Success Rate (%)',\n",
        "            yaxis_title='Average Duration (seconds)',\n",
        "            showlegend=False\n",
        "        )\n",
        "        \n",
        "        fig.show()\n",
        "    \n",
        "    def create_system_overview_dashboard(self):\n",
        "        \"\"\"Create comprehensive system overview dashboard\"\"\"\n",
        "        report = self.monitor.generate_performance_report()\n",
        "        \n",
        "        # Create a comprehensive dashboard\n",
        "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        \n",
        "        # System uptime and basic stats\n",
        "        stats_text = f\"\"\"System Uptime: {report['system_uptime']}\n",
        "Total Agents: {report['agent_summary']['total_agents']}\n",
        "Active Agents: {report['agent_summary']['active_agents']}\n",
        "Tasks Executed: {report['agent_summary']['total_tasks_executed']}\n",
        "Overall Success Rate: {report['agent_summary']['overall_success_rate']:.1f}%\n",
        "\n",
        "Total Workflows: {report['workflow_summary']['total_workflows']}\n",
        "Workflow Executions: {report['workflow_summary']['total_executions']}\n",
        "Workflow Success Rate: {report['workflow_summary']['workflow_success_rate']:.1f}%\n",
        "\n",
        "Learning Episodes: {report['learning_summary']['total_episodes']}\n",
        "Average Reward: {report['learning_summary']['average_reward']:.3f}\n",
        "Learning Trend: {report['learning_summary']['learning_trend']}\"\"\"\n",
        "        \n",
        "        ax1.text(0.1, 0.9, stats_text, transform=ax1.transAxes, fontsize=10,\n",
        "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue'))\n",
        "        ax1.set_title('System Overview')\n",
        "        ax1.axis('off')\n",
        "        \n",
        "        # Agent performance distribution\n",
        "        if self.monitor.agent_metrics:\n",
        "            success_rates = []\n",
        "            for agent_data in self.monitor.agent_metrics.values():\n",
        "                total = agent_data['total_tasks']\n",
        "                successful = agent_data['successful_tasks']\n",
        "                success_rate = (successful / total * 100) if total > 0 else 0\n",
        "                success_rates.append(success_rate)\n",
        "            \n",
        "            ax2.hist(success_rates, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "            ax2.set_title('Agent Success Rate Distribution')\n",
        "            ax2.set_xlabel('Success Rate (%)')\n",
        "            ax2.set_ylabel('Number of Agents')\n",
        "        else:\n",
        "            ax2.text(0.5, 0.5, 'No agent data available', ha='center', va='center', transform=ax2.transAxes)\n",
        "            ax2.set_title('Agent Success Rate Distribution')\n",
        "        \n",
        "        # Learning progress trend\n",
        "        if self.monitor.learning_metrics.get('reward_history'):\n",
        "            reward_history = list(self.monitor.learning_metrics['reward_history'])\n",
        "            recent_rewards = [entry['reward'] for entry in reward_history[-50:]]  # Last 50 episodes\n",
        "            \n",
        "            ax3.plot(recent_rewards, color='green', linewidth=2)\n",
        "            ax3.set_title('Recent Learning Progress (Last 50 Episodes)')\n",
        "            ax3.set_xlabel('Episode')\n",
        "            ax3.set_ylabel('Reward')\n",
        "            ax3.grid(True, alpha=0.3)\n",
        "        else:\n",
        "            ax3.text(0.5, 0.5, 'No learning data available', ha='center', va='center', transform=ax3.transAxes)\n",
        "            ax3.set_title('Recent Learning Progress')\n",
        "        \n",
        "        # Resource utilization (if available)\n",
        "        try:\n",
        "            cpu_percent = psutil.cpu_percent()\n",
        "            memory_percent = psutil.virtual_memory().percent\n",
        "            disk_percent = psutil.disk_usage('/').percent\n",
        "            \n",
        "            resources = ['CPU', 'Memory', 'Disk']\n",
        "            usage = [cpu_percent, memory_percent, disk_percent]\n",
        "            colors = ['red' if u > 80 else 'orange' if u > 60 else 'green' for u in usage]\n",
        "            \n",
        "            bars = ax4.bar(resources, usage, color=colors, alpha=0.7)\n",
        "            ax4.set_title('System Resource Utilization')\n",
        "            ax4.set_ylabel('Usage (%)')\n",
        "            ax4.set_ylim(0, 100)\n",
        "            \n",
        "            # Add percentage labels on bars\n",
        "            for bar, pct in zip(bars, usage):\n",
        "                height = bar.get_height()\n",
        "                ax4.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                        f'{pct:.1f}%', ha='center', va='bottom')\n",
        "        \n",
        "        except Exception as e:\n",
        "            ax4.text(0.5, 0.5, f'Resource data unavailable: {str(e)}', \n",
        "                    ha='center', va='center', transform=ax4.transAxes)\n",
        "            ax4.set_title('System Resource Utilization')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print('\\n📊 Dashboard generated successfully!')\n",
        "        print(f'📈 System has been running for {report[\"system_uptime\"]}')\n",
        "        print(f'🎯 Overall system performance: {report[\"agent_summary\"][\"overall_success_rate\"]:.1f}% success rate')\n",
        "\n",
        "# Initialize visualization dashboard\n",
        "viz_dashboard = Phase2VisualizationDashboard(phase2_monitor)\n",
        "print('📊 Phase 2/3 Visualization Dashboard initialized!')\n",
        "print('🎨 Ready to create performance charts and system overviews!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phase2_management_tools"
      },
      "outputs": [],
      "source": [
        "# 🛠️ Phase 2/3 Advanced Management Tools\n",
        "\n",
        "class Phase2ManagementSuite:\n",
        "    \"\"\"Comprehensive management suite for Phase 2/3 operations\"\"\"\n",
        "    \n",
        "    def __init__(self, monitor: Phase2MonitoringSystem, viz: Phase2VisualizationDashboard):\n",
        "        self.monitor = monitor\n",
        "        self.viz = viz\n",
        "        self.env_manager = ColabEnvironmentManager()\n",
        "        self.model_manager = ColabModelManager()\n",
        "        self.start_time = datetime.now()\n",
        "        \n",
        "        # Initialize management components\n",
        "        self.agent_registry = {}\n",
        "        self.workflow_registry = {}\n",
        "        self.resource_limits = {\n",
        "            'max_agents': 10,\n",
        "            'max_workflows': 20,\n",
        "            'memory_threshold': 80,  # percentage\n",
        "            'cpu_threshold': 90      # percentage\n",
        "        }\n",
        "    \n",
        "    def register_agent(self, agent_id: str, agent_config: Dict[str, Any]):\n",
        "        \"\"\"Register a new agent in the system\"\"\"\n",
        "        if len(self.agent_registry) >= self.resource_limits['max_agents']:\n",
        "            raise ValueError(f'Maximum number of agents ({self.resource_limits[\"max_agents\"]}) reached')\n",
        "        \n",
        "        self.agent_registry[agent_id] = {\n",
        "            'config': agent_config,\n",
        "            'status': 'registered',\n",
        "            'created_at': datetime.now(),\n",
        "            'last_heartbeat': datetime.now()\n",
        "        }\n",
        "        \n",
        "        print(f'🤖 Agent {agent_id} registered successfully')\n",
        "        return agent_id\n",
        "    \n",
        "    def register_workflow(self, workflow_id: str, workflow_config: Dict[str, Any]):\n",
        "        \"\"\"Register a new workflow in the system\"\"\"\n",
        "        if len(self.workflow_registry) >= self.resource_limits['max_workflows']:\n",
        "            raise ValueError(f'Maximum number of workflows ({self.resource_limits[\"max_workflows\"]}) reached')\n",
        "        \n",
        "        self.workflow_registry[workflow_id] = {\n",
        "            'config': workflow_config,\n",
        "            'status': 'registered',\n",
        "            'created_at': datetime.now(),\n",
        "            'executions': []\n",
        "        }\n",
        "        \n",
        "        print(f'🔄 Workflow {workflow_id} registered successfully')\n",
        "        return workflow_id\n",
        "    \n",
        "    def start_agent(self, agent_id: str):\n",
        "        \"\"\"Start an agent\"\"\"\n",
        "        if agent_id not in self.agent_registry:\n",
        "            raise ValueError(f'Agent {agent_id} not found in registry')\n",
        "        \n",
        "        # Check resource constraints\n",
        "        system_info = self.env_manager.get_system_info()\n",
        "        if system_info['memory']['percent'] > self.resource_limits['memory_threshold']:\n",
        "            raise ResourceWarning(f'Memory usage too high: {system_info[\"memory\"][\"percent\"]}%')\n",
        "        \n",
        "        self.agent_registry[agent_id]['status'] = 'active'\n",
        "        self.agent_registry[agent_id]['started_at'] = datetime.now()\n",
        "        \n",
        "        # Initialize monitoring for this agent\n",
        "        self.monitor.track_agent_performance(agent_id, {'status': 'started', 'action': 'initialization'})\n",
        "        \n",
        "        print(f'🚀 Agent {agent_id} started successfully')\n",
        "    \n",
        "    def stop_agent(self, agent_id: str):\n",
        "        \"\"\"Stop an agent\"\"\"\n",
        "        if agent_id not in self.agent_registry:\n",
        "            raise ValueError(f'Agent {agent_id} not found in registry')\n",
        "        \n",
        "        self.agent_registry[agent_id]['status'] = 'stopped'\n",
        "        self.agent_registry[agent_id]['stopped_at'] = datetime.now()\n",
        "        \n",
        "        print(f'⏹️ Agent {agent_id} stopped successfully')\n",
        "    \n",
        "    def execute_workflow(self, workflow_id: str, input_data: Dict[str, Any] = None):\n",
        "        \"\"\"Execute a workflow\"\"\"\n",
        "        if workflow_id not in self.workflow_registry:\n",
        "            raise ValueError(f'Workflow {workflow_id} not found in registry')\n",
        "        \n",
        "        execution_id = f'{workflow_id}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
        "        start_time = datetime.now()\n",
        "        \n",
        "        try:\n",
        "            # Simulate workflow execution\n",
        "            print(f'🔄 Executing workflow {workflow_id} (ID: {execution_id})')\n",
        "            \n",
        "            # Track workflow execution\n",
        "            self.monitor.track_workflow_execution(\n",
        "                workflow_id, \n",
        "                execution_id, \n",
        "                'success', \n",
        "                (datetime.now() - start_time).total_seconds()\n",
        "            )\n",
        "            \n",
        "            # Record execution\n",
        "            execution_record = {\n",
        "                'execution_id': execution_id,\n",
        "                'start_time': start_time,\n",
        "                'end_time': datetime.now(),\n",
        "                'status': 'success',\n",
        "                'input_data': input_data,\n",
        "                'output_data': {'result': 'workflow_completed', 'execution_id': execution_id}\n",
        "            }\n",
        "            \n",
        "            self.workflow_registry[workflow_id]['executions'].append(execution_record)\n",
        "            \n",
        "            print(f'✅ Workflow {workflow_id} completed successfully')\n",
        "            return execution_record['output_data']\n",
        "            \n",
        "        except Exception as e:\n",
        "            # Track failed execution\n",
        "            self.monitor.track_workflow_execution(\n",
        "                workflow_id, \n",
        "                execution_id, \n",
        "                'failed', \n",
        "                (datetime.now() - start_time).total_seconds()\n",
        "            )\n",
        "            \n",
        "            print(f'❌ Workflow {workflow_id} failed: {str(e)}')\n",
        "            raise\n",
        "    \n",
        "    def health_check(self) -> Dict[str, Any]:\n",
        "        \"\"\"Perform comprehensive system health check\"\"\"\n",
        "        health_status = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'uptime': str(datetime.now() - self.start_time),\n",
        "            'system': 'healthy',\n",
        "            'components': {}\n",
        "        }\n",
        "        \n",
        "        # Check system resources\n",
        "        system_info = self.env_manager.get_system_info()\n",
        "        \n",
        "        # Memory check\n",
        "        memory_status = 'healthy'\n",
        "        if system_info['memory']['percent'] > self.resource_limits['memory_threshold']:\n",
        "            memory_status = 'warning'\n",
        "        if system_info['memory']['percent'] > 95:\n",
        "            memory_status = 'critical'\n",
        "        \n",
        "        health_status['components']['memory'] = {\n",
        "            'status': memory_status,\n",
        "            'usage_percent': system_info['memory']['percent'],\n",
        "            'available_gb': system_info['memory']['available'] / (1024**3)\n",
        "        }\n",
        "        \n",
        "        # CPU check\n",
        "        cpu_status = 'healthy'\n",
        "        if system_info['cpu_percent'] > self.resource_limits['cpu_threshold']:\n",
        "            cpu_status = 'warning'\n",
        "        if system_info['cpu_percent'] > 98:\n",
        "            cpu_status = 'critical'\n",
        "        \n",
        "        health_status['components']['cpu'] = {\n",
        "            'status': cpu_status,\n",
        "            'usage_percent': system_info['cpu_percent'],\n",
        "            'core_count': system_info['cpu_count']\n",
        "        }\n",
        "        \n",
        "        # Agent health\n",
        "        active_agents = sum(1 for agent in self.agent_registry.values() if agent['status'] == 'active')\n",
        "        health_status['components']['agents'] = {\n",
        "            'status': 'healthy',\n",
        "            'total_registered': len(self.agent_registry),\n",
        "            'active_count': active_agents,\n",
        "            'capacity_used': f'{len(self.agent_registry)}/{self.resource_limits[\"max_agents\"]}'\n",
        "        }\n",
        "        \n",
        "        # Workflow health\n",
        "        health_status['components']['workflows'] = {\n",
        "            'status': 'healthy',\n",
        "            'total_registered': len(self.workflow_registry),\n",
        "            'capacity_used': f'{len(self.workflow_registry)}/{self.resource_limits[\"max_workflows\"]}'\n",
        "        }\n",
        "        \n",
        "        # Overall system status\n",
        "        component_statuses = [comp['status'] for comp in health_status['components'].values()]\n",
        "        if 'critical' in component_statuses:\n",
        "            health_status['system'] = 'critical'\n",
        "        elif 'warning' in component_statuses:\n",
        "            health_status['system'] = 'warning'\n",
        "        \n",
        "        return health_status\n",
        "    \n",
        "    def cleanup_resources(self):\n",
        "        \"\"\"Clean up system resources\"\"\"\n",
        "        print('🧹 Starting resource cleanup...')\n",
        "        \n",
        "        # Stop inactive agents\n",
        "        inactive_agents = []\n",
        "        for agent_id, agent_info in self.agent_registry.items():\n",
        "            if agent_info['status'] == 'active':\n",
        "                # Check if agent has been inactive for more than 10 minutes\n",
        "                if (datetime.now() - agent_info['last_heartbeat']).seconds > 600:\n",
        "                    inactive_agents.append(agent_id)\n",
        "        \n",
        "        for agent_id in inactive_agents:\n",
        "            self.stop_agent(agent_id)\n",
        "            print(f'🧹 Stopped inactive agent: {agent_id}')\n",
        "        \n",
        "        # Clear old workflow executions (keep only last 100)\n",
        "        for workflow_id, workflow_info in self.workflow_registry.items():\n",
        "            if len(workflow_info['executions']) > 100:\n",
        "                workflow_info['executions'] = workflow_info['executions'][-100:]\n",
        "                print(f'🧹 Cleaned old executions for workflow: {workflow_id}')\n",
        "        \n",
        "        # Force garbage collection\n",
        "        import gc\n",
        "        gc.collect()\n",
        "        \n",
        "        print('✅ Resource cleanup completed')\n",
        "    \n",
        "    def generate_management_report(self) -> Dict[str, Any]:\n",
        "        \"\"\"Generate comprehensive management report\"\"\"\n",
        "        health = self.health_check()\n",
        "        performance = self.monitor.generate_performance_report()\n",
        "        \n",
        "        report = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'system_health': health,\n",
        "            'performance_metrics': performance,\n",
        "            'resource_utilization': {\n",
        "                'agents': {\n",
        "                    'registered': len(self.agent_registry),\n",
        "                    'active': sum(1 for a in self.agent_registry.values() if a['status'] == 'active'),\n",
        "                    'capacity': self.resource_limits['max_agents']\n",
        "                },\n",
        "                'workflows': {\n",
        "                    'registered': len(self.workflow_registry),\n",
        "                    'total_executions': sum(len(w['executions']) for w in self.workflow_registry.values()),\n",
        "                    'capacity': self.resource_limits['max_workflows']\n",
        "                }\n",
        "            },\n",
        "            'recommendations': self._generate_recommendations(health, performance)\n",
        "        }\n",
        "        \n",
        "        return report\n",
        "    \n",
        "    def _generate_recommendations(self, health: Dict, performance: Dict) -> List[str]:\n",
        "        \"\"\"Generate system recommendations based on health and performance\"\"\"\n",
        "        recommendations = []\n",
        "        \n",
        "        # Memory recommendations\n",
        "        if health['components']['memory']['status'] == 'warning':\n",
        "            recommendations.append('Consider reducing the number of active agents or workflows')\n",
        "        elif health['components']['memory']['status'] == 'critical':\n",
        "            recommendations.append('URGENT: Memory usage critical - stop non-essential processes')\n",
        "        \n",
        "        # CPU recommendations\n",
        "        if health['components']['cpu']['status'] == 'warning':\n",
        "            recommendations.append('High CPU usage detected - consider optimizing agent algorithms')\n",
        "        \n",
        "        # Performance recommendations\n",
        "        if performance['agent_summary']['overall_success_rate'] < 80:\n",
        "            recommendations.append('Agent success rate below 80% - review agent configurations')\n",
        "        \n",
        "        if performance['workflow_summary']['workflow_success_rate'] < 90:\n",
        "            recommendations.append('Workflow success rate below 90% - check workflow definitions')\n",
        "        \n",
        "        # Learning recommendations\n",
        "        if performance['learning_summary']['learning_trend'] == 'declining':\n",
        "            recommendations.append('Learning performance declining - adjust learning parameters')\n",
        "        \n",
        "        if not recommendations:\n",
        "            recommendations.append('System operating optimally - no immediate actions required')\n",
        "        \n",
        "        return recommendations\n",
        "\n",
        "# Initialize Phase 2/3 Management Suite\n",
        "management_suite = Phase2ManagementSuite(phase2_monitor, viz_dashboard)\n",
        "print('🛠️ Phase 2/3 Management Suite initialized!')\n",
        "print('📊 Ready for advanced system management and monitoring!')\n",
        "\n",
        "# Demonstrate management capabilities\n",
        "print('\\n🔍 System Health Check:')\n",
        "health_report = management_suite.health_check()\n",
        "print(f'System Status: {health_report[\"system\"]} 📊')\n",
        "print(f'Uptime: {health_report[\"uptime\"]} ⏱️')\n",
        "print(f'Memory Usage: {health_report[\"components\"][\"memory\"][\"usage_percent\"]:.1f}% 💾')\n",
        "print(f'CPU Usage: {health_report[\"components\"][\"cpu\"][\"usage_percent\"]:.1f}% 🖥️')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utilities_header"
      },
      "source": [
        "# 🛠️ Colab Utilities and Helper Functions - Enhanced for Phase 2/3\n",
        "\n",
        "## AI Coding Assistant - Advanced Utility Functions\n",
        "\n",
        "This notebook contains enhanced utility functions and helper tools for managing your AI coding assistant in Google Colab with Phase 2/3 capabilities.\n",
        "\n",
        "### 🎯 What's Included\n",
        "\n",
        "- **🔧 Environment Management**: Setup and configuration utilities\n",
        "- **📊 Model Management**: Load, save, and manage AI models\n",
        "- **🔄 Data Sync**: Synchronize data between local and cloud\n",
        "- **📱 Service Management**: Start, stop, and monitor services\n",
        "- **🐛 Debugging Tools**: Logging and error handling utilities\n",
        "- **📈 Performance Monitoring**: Track resource usage and performance\n",
        "- **🤖 Agent Monitoring**: Monitor autonomous agents and orchestration\n",
        "- **🧠 Learning Analytics**: Track learning system performance\n",
        "- **🔄 Workflow Management**: Monitor and manage complex workflows\n",
        "- **🎯 Resource Optimization**: Advanced resource allocation and optimization\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_utilities"
      },
      "outputs": [],
      "source": [
        "# 📦 Import Required Libraries - Enhanced for Phase 2/3\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import psutil\n",
        "import logging\n",
        "import subprocess\n",
        "import asyncio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Any, Optional, Union\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "# Install additional utilities if needed\n",
        "utilities_packages = [\n",
        "    'psutil',\n",
        "    'GPUtil', \n",
        "    'plotly',\n",
        "    'matplotlib',\n",
        "    'seaborn',\n",
        "    'redis',\n",
        "    'celery',\n",
        "    'prometheus-client'\n",
        "]\n",
        "\n",
        "for package in utilities_packages:\n",
        "    try:\n",
        "        __import__(package.replace('-', '_'))\n",
        "    except ImportError:\n",
        "        !pip install -q {package}\n",
        "\n",
        "import psutil\n",
        "import GPUtil\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print('✅ Enhanced utilities imported successfully!')\n",
        "print('🚀 Phase 2/3 monitoring capabilities ready!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "environment_utils"
      },
      "source": [
        "## 🔧 Environment Management Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "environment_manager"
      },
      "outputs": [],
      "source": [
        "# 🔧 Environment Management Class\n",
        "\n",
        "class ColabEnvironmentManager:\n",
        "    def __init__(self, project_root: str = '/content/ai_assistant'):\n",
        "        self.project_root = Path(project_root)\n",
        "        self.config_file = self.project_root / 'config' / 'colab_config.json'\n",
        "        self.log_file = self.project_root / 'logs' / 'colab.log'\n",
        "        self.setup_logging()\n",
        "    \n",
        "    def setup_logging(self):\n",
        "        \"\"\"Setup logging configuration\"\"\"\n",
        "        os.makedirs(self.log_file.parent, exist_ok=True)\n",
        "        \n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "            handlers=[\n",
        "                logging.FileHandler(self.log_file),\n",
        "                logging.StreamHandler(sys.stdout)\n",
        "            ]\n",
        "        )\n",
        "        self.logger = logging.getLogger('ColabEnvironment')\n",
        "    \n",
        "    def get_system_info(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get comprehensive system information\"\"\"\n",
        "        info = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'python_version': sys.version,\n",
        "            'platform': sys.platform,\n",
        "            'cpu_count': psutil.cpu_count(),\n",
        "            'cpu_percent': psutil.cpu_percent(interval=1),\n",
        "            'memory': {\n",
        "                'total': psutil.virtual_memory().total,\n",
        "                'available': psutil.virtual_memory().available,\n",
        "                'percent': psutil.virtual_memory().percent\n",
        "            },\n",
        "            'disk': {\n",
        "                'total': psutil.disk_usage('/').total,\n",
        "                'free': psutil.disk_usage('/').free,\n",
        "                'percent': psutil.disk_usage('/').percent\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        # GPU information\n",
        "        try:\n",
        "            gpus = GPUtil.getGPUs()\n",
        "            info['gpu'] = []\n",
        "            for gpu in gpus:\n",
        "                info['gpu'].append({\n",
        "                    'name': gpu.name,\n",
        "                    'memory_total': gpu.memoryTotal,\n",
        "                    'memory_used': gpu.memoryUsed,\n",
        "                    'memory_free': gpu.memoryFree,\n",
        "                    'temperature': gpu.temperature,\n",
        "                    'load': gpu.load\n",
        "                })\n",
        "        except Exception as e:\n",
        "            info['gpu'] = f'GPU info unavailable: {str(e)}'\n",
        "        \n",
        "        return info\n",
        "    \n",
        "    def save_config(self, config: Dict[str, Any]):\n",
        "        \"\"\"Save configuration to file\"\"\"\n",
        "        os.makedirs(self.config_file.parent, exist_ok=True)\n",
        "        with open(self.config_file, 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "        self.logger.info(f'Configuration saved to {self.config_file}')\n",
        "    \n",
        "    def load_config(self) -> Dict[str, Any]:\n",
        "        \"\"\"Load configuration from file\"\"\"\n",
        "        if self.config_file.exists():\n",
        "            with open(self.config_file, 'r') as f:\n",
        "                return json.load(f)\n",
        "        return {}\n",
        "    \n",
        "    def create_project_structure(self):\n",
        "        \"\"\"Create complete project directory structure\"\"\"\n",
        "        directories = [\n",
        "            'backend/app/api',\n",
        "            'backend/app/core',\n",
        "            'backend/app/models',\n",
        "            'backend/app/services',\n",
        "            'backend/app/utils',\n",
        "            'frontend/src/components',\n",
        "            'frontend/src/pages',\n",
        "            'frontend/src/utils',\n",
        "            'data/training',\n",
        "            'data/models',\n",
        "            'data/datasets',\n",
        "            'logs',\n",
        "            'config',\n",
        "            'scripts',\n",
        "            'tests'\n",
        "        ]\n",
        "        \n",
        "        for directory in directories:\n",
        "            dir_path = self.project_root / directory\n",
        "            os.makedirs(dir_path, exist_ok=True)\n",
        "            \n",
        "            # Create __init__.py for Python packages\n",
        "            if 'backend' in directory or 'frontend' in directory:\n",
        "                init_file = dir_path / '__init__.py'\n",
        "                if not init_file.exists():\n",
        "                    init_file.touch()\n",
        "        \n",
        "        self.logger.info(f'Project structure created at {self.project_root}')\n",
        "    \n",
        "    def install_requirements(self, requirements: List[str]):\n",
        "        \"\"\"Install Python packages\"\"\"\n",
        "        for package in requirements:\n",
        "            try:\n",
        "                subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', package], \n",
        "                             check=True, capture_output=True, text=True)\n",
        "                self.logger.info(f'✅ Installed {package}')\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                self.logger.error(f'❌ Failed to install {package}: {e}')\n",
        "    \n",
        "    def check_gpu_availability(self) -> Dict[str, Any]:\n",
        "        \"\"\"Check GPU availability and status\"\"\"\n",
        "        try:\n",
        "            import torch\n",
        "            gpu_info = {\n",
        "                'torch_cuda_available': torch.cuda.is_available(),\n",
        "                'torch_cuda_device_count': torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
        "            }\n",
        "            \n",
        "            if torch.cuda.is_available():\n",
        "                gpu_info['current_device'] = torch.cuda.current_device()\n",
        "                gpu_info['device_name'] = torch.cuda.get_device_name()\n",
        "                gpu_info['memory_allocated'] = torch.cuda.memory_allocated()\n",
        "                gpu_info['memory_reserved'] = torch.cuda.memory_reserved()\n",
        "            \n",
        "            return gpu_info\n",
        "        except ImportError:\n",
        "            return {'error': 'PyTorch not available'}\n",
        "\n",
        "# Initialize environment manager\n",
        "env_manager = ColabEnvironmentManager()\n",
        "print('✅ Environment manager initialized!')\n",
        "\n",
        "# Display system information\n",
        "system_info = env_manager.get_system_info()\n",
        "print('\\n📊 System Information:')\n",
        "print(f\"CPU: {system_info['cpu_count']} cores, {system_info['cpu_percent']:.1f}% usage\")\n",
        "print(f\"Memory: {system_info['memory']['percent']:.1f}% used\")\n",
        "print(f\"Disk: {system_info['disk']['percent']:.1f}% used\")\n",
        "\n",
        "gpu_info = env_manager.check_gpu_availability()\n",
        "if gpu_info.get('torch_cuda_available'):\n",
        "    print(f\"🚀 GPU Available: {gpu_info['device_name']}\")\n",
        "else:\n",
        "    print('⚠️ No GPU available')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_utils"
      },
      "source": [
        "## 🤖 Model Management Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_manager"
      },
      "outputs": [],
      "source": [
        "# 🤖 Model Management Class\n",
        "\n",
        "class ColabModelManager:\n",
        "    def __init__(self, models_dir: str = '/content/ai_assistant/data/models'):\n",
        "        self.models_dir = Path(models_dir)\n",
        "        os.makedirs(self.models_dir, exist_ok=True)\n",
        "        self.logger = logging.getLogger('ModelManager')\n",
        "    \n",
        "    def download_model(self, model_name: str, model_type: str = 'huggingface') -> bool:\n",
        "        \"\"\"Download a model from various sources\"\"\"\n",
        "        try:\n",
        "            if model_type == 'huggingface':\n",
        "                from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "                \n",
        "                self.logger.info(f'Downloading {model_name} from Hugging Face...')\n",
        "                \n",
        "                # Download tokenizer\n",
        "                tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "                tokenizer_path = self.models_dir / f'{model_name.replace(\"/\", \"_\")}_tokenizer'\n",
        "                tokenizer.save_pretrained(tokenizer_path)\n",
        "                \n",
        "                # Download model\n",
        "                model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "                model_path = self.models_dir / f'{model_name.replace(\"/\", \"_\")}_model'\n",
        "                model.save_pretrained(model_path)\n",
        "                \n",
        "                self.logger.info(f'✅ Model {model_name} downloaded successfully')\n",
        "                return True\n",
        "            \n",
        "            else:\n",
        "                self.logger.error(f'Unsupported model type: {model_type}')\n",
        "                return False\n",
        "                \n",
        "        except Exception as e:\n",
        "            self.logger.error(f'Failed to download {model_name}: {str(e)}')\n",
        "            return False\n",
        "    \n",
        "    def list_local_models(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"List all locally stored models\"\"\"\n",
        "        models = []\n",
        "        \n",
        "        for model_dir in self.models_dir.iterdir():\n",
        "            if model_dir.is_dir():\n",
        "                model_info = {\n",
        "                    'name': model_dir.name,\n",
        "                    'path': str(model_dir),\n",
        "                    'size_mb': sum(f.stat().st_size for f in model_dir.rglob('*') if f.is_file()) / (1024 * 1024),\n",
        "                    'created': datetime.fromtimestamp(model_dir.stat().st_ctime).isoformat()\n",
        "                }\n",
        "                models.append(model_info)\n",
        "        \n",
        "        return models\n",
        "    \n",
        "    def delete_model(self, model_name: str) -> bool:\n",
        "        \"\"\"Delete a local model\"\"\"\n",
        "        try:\n",
        "            model_path = self.models_dir / model_name\n",
        "            if model_path.exists():\n",
        "                import shutil\n",
        "                shutil.rmtree(model_path)\n",
        "                self.logger.info(f'✅ Model {model_name} deleted')\n",
        "                return True\n",
        "            else:\n",
        "                self.logger.warning(f'Model {model_name} not found')\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            self.logger.error(f'Failed to delete {model_name}: {str(e)}')\n",
        "            return False\n",
        "    \n",
        "    def get_model_info(self, model_name: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Get detailed information about a model\"\"\"\n",
        "        model_path = self.models_dir / model_name\n",
        "        \n",
        "        if not model_path.exists():\n",
        "            return None\n",
        "        \n",
        "        try:\n",
        "            # Try to load config if available\n",
        "            config_file = model_path / 'config.json'\n",
        "            config = {}\n",
        "            if config_file.exists():\n",
        "                with open(config_file, 'r') as f:\n",
        "                    config = json.load(f)\n",
        "            \n",
        "            return {\n",
        "                'name': model_name,\n",
        "                'path': str(model_path),\n",
        "                'config': config,\n",
        "                'files': [f.name for f in model_path.iterdir()],\n",
        "                'size_mb': sum(f.stat().st_size for f in model_path.rglob('*') if f.is_file()) / (1024 * 1024)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.error(f'Error getting model info: {str(e)}')\n",
        "            return None\n",
        "\n",
        "# Initialize model manager\n",
        "model_manager = ColabModelManager()\n",
        "print('✅ Model manager initialized!')\n",
        "\n",
        "# List available models\n",
        "local_models = model_manager.list_local_models()\n",
        "print(f'\\n📦 Local Models: {len(local_models)} found')\n",
        "for model in local_models:\n",
        "    print(f\"  - {model['name']} ({model['size_mb']:.1f} MB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "service_utils"
      },
      "source": [
        "## 🔄 Service Management Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "service_manager"
      },
      "outputs": [],
      "source": [
        "# 🔄 Service Management Class\n",
        "\n",
        "import threading\n",
        "import queue\n",
        "from contextlib import contextmanager\n",
        "\n",
        "class ColabServiceManager:\n",
        "    def __init__(self):\n",
        "        self.services = {}\n",
        "        self.logger = logging.getLogger('ServiceManager')\n",
        "    \n",
        "    def start_backend(self, port: int = 8000, host: str = '0.0.0.0') -> bool:\n",
        "        \"\"\"Start the FastAPI backend service\"\"\"\n",
        "        try:\n",
        "            import uvicorn\n",
        "            from backend.app.main import app\n",
        "            \n",
        "            # Start in a separate thread\n",
        "            def run_server():\n",
        "                uvicorn.run(app, host=host, port=port, log_level=\"info\")\n",
        "            \n",
        "            backend_thread = threading.Thread(target=run_server, daemon=True)\n",
        "            backend_thread.start()\n",
        "            \n",
        "            self.services['backend'] = {\n",
        "                'thread': backend_thread,\n",
        "                'port': port,\n",
        "                'host': host,\n",
        "                'status': 'running'\n",
        "            }\n",
        "            \n",
        "            self.logger.info(f'✅ Backend started on {host}:{port}')\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            self.logger.error(f'Failed to start backend: {str(e)}')\n",
        "            return False\n",
        "    \n",
        "    def start_frontend(self, port: int = 8501) -> bool:\n",
        "        \"\"\"Start the Streamlit frontend service\"\"\"\n",
        "        try:\n",
        "            # Create a simple Streamlit app\n",
        "            frontend_code = '''\n",
        "import streamlit as st\n",
        "import requests\n",
        "import json\n",
        "\n",
        "st.set_page_config(page_title=\"AI Coding Assistant\", page_icon=\"🤖\")\n",
        "\n",
        "st.title(\"🤖 AI Coding Assistant\")\n",
        "st.markdown(\"### Powered by Google Colab\")\n",
        "\n",
        "# API endpoint\n",
        "API_BASE = \"http://localhost:8000\"\n",
        "\n",
        "# Chat interface\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "if prompt := st.chat_input(\"Ask me to generate code...\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "    \n",
        "    with st.chat_message(\"assistant\"):\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                f\"{API_BASE}/api/code/generate\",\n",
        "                json={\"prompt\": prompt, \"language\": \"python\"}\n",
        "            )\n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                code = result.get(\"code\", \"No code generated\")\n",
        "                st.code(code, language=\"python\")\n",
        "                st.session_state.messages.append({\"role\": \"assistant\", \"content\": code})\n",
        "            else:\n",
        "                st.error(\"Failed to generate code\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error: {str(e)}\")\n",
        "            '''\n",
        "            \n",
        "            # Save frontend app\n",
        "            frontend_file = '/content/ai_assistant/frontend/streamlit_app.py'\n",
        "            os.makedirs(os.path.dirname(frontend_file), exist_ok=True)\n",
        "            with open(frontend_file, 'w') as f:\n",
        "                f.write(frontend_code.strip())\n",
        "            \n",
        "            # Start Streamlit\n",
        "            def run_streamlit():\n",
        "                os.system(f'streamlit run {frontend_file} --server.port {port} --server.headless true')\n",
        "            \n",
        "            frontend_thread = threading.Thread(target=run_streamlit, daemon=True)\n",
        "            frontend_thread.start()\n",
        "            \n",
        "            self.services['frontend'] = {\n",
        "                'thread': frontend_thread,\n",
        "                'port': port,\n",
        "                'status': 'running'\n",
        "            }\n",
        "            \n",
        "            self.logger.info(f'✅ Frontend started on port {port}')\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            self.logger.error(f'Failed to start frontend: {str(e)}')\n",
        "            return False\n",
        "    \n",
        "    def setup_ngrok(self, port: int, auth_token: str = None) -> Optional[str]:\n",
        "        \"\"\"Setup ngrok tunnel for external access\"\"\"\n",
        "        try:\n",
        "            from pyngrok import ngrok\n",
        "            \n",
        "            if auth_token:\n",
        "                ngrok.set_auth_token(auth_token)\n",
        "            \n",
        "            # Create tunnel\n",
        "            tunnel = ngrok.connect(port)\n",
        "            public_url = tunnel.public_url\n",
        "            \n",
        "            self.logger.info(f'✅ Ngrok tunnel created: {public_url}')\n",
        "            return public_url\n",
        "            \n",
        "        except Exception as e:\n",
        "            self.logger.error(f'Failed to setup ngrok: {str(e)}')\n",
        "            return None\n",
        "    \n",
        "    def get_service_status(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get status of all services\"\"\"\n",
        "        status = {}\n",
        "        \n",
        "        for service_name, service_info in self.services.items():\n",
        "            status[service_name] = {\n",
        "                'status': service_info['status'],\n",
        "                'port': service_info.get('port'),\n",
        "                'thread_alive': service_info['thread'].is_alive() if 'thread' in service_info else False\n",
        "            }\n",
        "        \n",
        "        return status\n",
        "    \n",
        "    def stop_service(self, service_name: str) -> bool:\n",
        "        \"\"\"Stop a specific service\"\"\"\n",
        "        if service_name in self.services:\n",
        "            try:\n",
        "                # Note: In Colab, we can't easily stop threads\n",
        "                # This is a limitation of the environment\n",
        "                self.services[service_name]['status'] = 'stopped'\n",
        "                self.logger.info(f'Service {service_name} marked as stopped')\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                self.logger.error(f'Error stopping {service_name}: {str(e)}')\n",
        "                return False\n",
        "        else:\n",
        "            self.logger.warning(f'Service {service_name} not found')\n",
        "            return False\n",
        "\n",
        "# Initialize service manager\n",
        "service_manager = ColabServiceManager()\n",
        "print('✅ Service manager initialized!')"
      ]
    }
  ]
}